{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.13.0-rc1 \n",
      "At least 2.13 required\n",
      "Python Platform: macOS-13.4.1-arm64-arm-64bit\n",
      "Tensor Flow Version: 2.13.0-rc1\n",
      "Python 3.10.11 (v3.10.11:7d4cc5aa85, Apr  4 2023, 19:05:19) [Clang 13.0.0 (clang-1300.0.29.30)]\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from google.colab import drive\n",
    "from skimage import measure\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib.patches as mpatches\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import sys, os, platform\n",
    "\n",
    "print('Tensorflow version:',tf.__version__)\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Python {sys.version}\")\n",
    "gpu = len(tf.config.list_physical_devices(\"GPU\")) > 0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SLICES = 64\n",
    "DIMENSION = 256\n",
    "PROJECT_FOLDER = \"/content/drive/MyDrive/Dmitrii_Utkin/model_3dunet\"  # \"/Users/dutking/LOCAL/AI_uni/radlogix\"\n",
    "DS_FOLDER = \"dataset\"  # \"dataset/tfrecords_1to1\"\n",
    "TRAIN_DS_FILE = \"train.tfrecords\"\n",
    "VAL_DS_FILE = \"val.tfrecords\"\n",
    "TEST_DS_FILE = \"test.tfrecords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(record):\n",
    "    name_to_features = {\n",
    "        \"shape\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"feature\": tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    return tf.io.parse_single_example(record, name_to_features)\n",
    "\n",
    "\n",
    "def decode_record(record):\n",
    "    feature = tf.io.decode_raw(\n",
    "        record[\"feature\"],\n",
    "        out_type=\"float64\",\n",
    "        little_endian=True,\n",
    "        fixed_length=None,\n",
    "        name=None,\n",
    "    )\n",
    "    label = tf.io.decode_raw(\n",
    "        record[\"label\"],\n",
    "        out_type=\"int16\",\n",
    "        little_endian=True,\n",
    "        fixed_length=None,\n",
    "        name=None,\n",
    "    )\n",
    "    shape = tf.io.decode_raw(\n",
    "        record[\"shape\"],\n",
    "        out_type=\"int64\",\n",
    "        little_endian=True,\n",
    "        fixed_length=None,\n",
    "        name=None,\n",
    "    )\n",
    "    label = tf.cast(tf.reshape(label, shape), dtype=tf.float32)\n",
    "    feature = tf.cast(tf.reshape(feature, shape), dtype=tf.float64)\n",
    "    label.set_shape((TARGET_SLICES, DIMENSION, DIMENSION, 1))\n",
    "    feature.set_shape((TARGET_SLICES, DIMENSION, DIMENSION, 1))\n",
    "    return (feature, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"CPU\"):\n",
    "    train_ds = (\n",
    "        tf.data.TFRecordDataset(\n",
    "            os.path.join(PROJECT_FOLDER, DS_FOLDER, TRAIN_DS_FILE),\n",
    "            compression_type=\"GZIP\",\n",
    "        )\n",
    "        .map(parse_record, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .map(decode_record, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    # norm_ds = train_ds.map(lambda x, y, z: x)\n",
    "    # normalization_layer = tf.keras.layers.Normalization(axis=None)\n",
    "    # normalization_layer.adapt(norm_ds)\n",
    "    # del norm_ds\n",
    "\n",
    "    train_ds = (\n",
    "        train_ds.cache()\n",
    "        .shuffle(74, reshuffle_each_iteration=False)  # train_ds.cardinality().numpy()\n",
    "        .batch(1)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    val_ds = (\n",
    "        tf.data.TFRecordDataset(\n",
    "            os.path.join(PROJECT_FOLDER, DS_FOLDER, VAL_DS_FILE),\n",
    "            compression_type=\"GZIP\",\n",
    "        )\n",
    "        .map(parse_record, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .map(decode_record, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .cache()\n",
    "        .shuffle(20, reshuffle_each_iteration=False)\n",
    "        .batch(1)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    test_ds = (\n",
    "        tf.data.TFRecordDataset(\n",
    "            os.path.join(PROJECT_FOLDER, DS_FOLDER, TEST_DS_FILE),\n",
    "            compression_type=\"GZIP\",\n",
    "        )\n",
    "        .map(parse_record, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .map(decode_record, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .cache()\n",
    "        .batch(1)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to enable loss function to be flexibly used for\n",
    "# both 2D or 3D image segmentation - source: https://github.com/frankkramer-lab/MIScnn\n",
    "def identify_axis(shape):\n",
    "    # Three dimensional\n",
    "    if len(shape) == 5:\n",
    "        return [1, 2, 3]\n",
    "    # Two dimensional\n",
    "    elif len(shape) == 4:\n",
    "        return [1, 2]\n",
    "    # Exception - Unknown\n",
    "    else:\n",
    "        raise ValueError(\"Metric: Shape of tensor is neither 2D or 3D.\")\n",
    "\n",
    "\n",
    "def dice_coefficient(delta=0.5, smooth=0.000001):\n",
    "    \"\"\"The Dice similarity coefficient, also known as the Sørensen–Dice index or simply Dice coefficient, is a statistical tool which measures the similarity between two sets of data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.5\n",
    "    smooth : float, optional\n",
    "        smoothing constant to prevent division by zero errors, by default 0.000001\n",
    "    \"\"\"\n",
    "\n",
    "    def loss_function(y_true, y_pred):\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)\n",
    "        y_pred = tf.where(y_pred >= 0.5, 1.0, 0.0)\n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1 - y_pred), axis=axis)\n",
    "        fp = K.sum((1 - y_true) * y_pred, axis=axis)\n",
    "        dice_class = (tp + smooth) / (tp + delta * fn + (1 - delta) * fp + smooth)\n",
    "        # Average class scores\n",
    "        dice = K.mean(dice_class)\n",
    "\n",
    "        return dice\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "\n",
    "def focal_tversky_loss(delta=0.7, gamma=0.75, smooth=0.000001):\n",
    "    \"\"\"A Novel Focal Tversky loss function with improved Attention U-Net for lesion segmentation\n",
    "    Link: https://arxiv.org/abs/1810.07842\n",
    "    Parameters\n",
    "    ----------\n",
    "    gamma : float, optional\n",
    "        focal parameter controls degree of down-weighting of easy examples, by default 0.75\n",
    "    \"\"\"\n",
    "\n",
    "    def loss_function(y_true, y_pred):\n",
    "        # Clip values to prevent division by zero error\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)\n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1 - y_pred), axis=axis)\n",
    "        fp = K.sum((1 - y_true) * y_pred, axis=axis)\n",
    "        tversky_class = (tp + smooth) / (tp + delta * fn + (1 - delta) * fp + smooth)\n",
    "        # Average class scores\n",
    "        focal_tversky_loss = K.mean(K.pow((1 - tversky_class), gamma))\n",
    "\n",
    "        return focal_tversky_loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "\n",
    "def symmetric_focal_tversky_loss(delta=0.7, gamma=0.75):\n",
    "    \"\"\"This is the implementation for binary segmentation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.7\n",
    "    gamma : float, optional\n",
    "        focal parameter controls degree of down-weighting of easy examples, by default 0.75\n",
    "    \"\"\"\n",
    "\n",
    "    def loss_function(y_true, y_pred):\n",
    "        # Clip values to prevent division by zero error\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)\n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1 - y_pred), axis=axis)\n",
    "        fp = K.sum((1 - y_true) * y_pred, axis=axis)\n",
    "        dice_class = (tp + epsilon) / (tp + delta * fn + (1 - delta) * fp + epsilon)\n",
    "\n",
    "        # calculate losses separately for each class, enhancing both classes\n",
    "        back_dice = (1 - dice_class[:, 0]) * K.pow(1 - dice_class[:, 0], -gamma)\n",
    "        fore_dice = (1 - dice_class[:, 1]) * K.pow(1 - dice_class[:, 1], -gamma)\n",
    "\n",
    "        # Average class scores\n",
    "        loss = K.mean(tf.stack([back_dice, fore_dice], axis=-1))\n",
    "        return loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "\n",
    "def asymmetric_focal_tversky_loss(delta=0.7, gamma=0.75):\n",
    "    \"\"\"This is the implementation for binary segmentation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.7\n",
    "    gamma : float, optional\n",
    "        focal parameter controls degree of down-weighting of easy examples, by default 0.75\n",
    "    \"\"\"\n",
    "\n",
    "    def loss_function(y_true, y_pred):\n",
    "        # Clip values to prevent division by zero error\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)\n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1 - y_pred), axis=axis)\n",
    "        fp = K.sum((1 - y_true) * y_pred, axis=axis)\n",
    "        dice_class = (tp + epsilon) / (tp + delta * fn + (1 - delta) * fp + epsilon)\n",
    "\n",
    "        # calculate losses separately for each class, only enhancing foreground class\n",
    "        back_dice = 1 - dice_class[:, 0]\n",
    "        fore_dice = (1 - dice_class[:, 1]) * K.pow(1 - dice_class[:, 1], -gamma)\n",
    "\n",
    "        # Average class scores\n",
    "        loss = K.mean(tf.stack([back_dice, fore_dice], axis=-1))\n",
    "        return loss\n",
    "\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, filters, activation=\"relu\"):\n",
    "    \"\"\"\n",
    "    Convolution block of a UNet encoder\n",
    "    \"\"\"\n",
    "    x = tf.keras.layers.Conv3D(\n",
    "        filters, (3, 3, 3), padding=\"same\", activation=activation\n",
    "    )(input)\n",
    "    x = tf.keras.layers.Conv3D(\n",
    "        filters, (3, 3, 3), padding=\"same\", activation=activation\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def encoder_block(input, filters):\n",
    "    \"\"\"\n",
    "    Encoder block of a UNet passes the result from the convolution block\n",
    "    above to a max pooling layer\n",
    "    \"\"\"\n",
    "    x = conv_block(input, filters)\n",
    "    p = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "\n",
    "def attention_gate(g, s, filters):  #! MOD\n",
    "    Wg = tf.keras.layers.Conv3D(filters, (1, 1, 1), padding=\"same\")(g)\n",
    "    Wg = tf.keras.layers.BatchNormalization()(Wg)\n",
    "\n",
    "    Ws = tf.keras.layers.Conv3D(filters, (1, 1, 1), padding=\"same\")(s)\n",
    "    Ws = tf.keras.layers.BatchNormalization()(Ws)\n",
    "\n",
    "    out = tf.keras.activations.relu(Wg + Ws)\n",
    "    out = tf.keras.layers.Conv3D(filters, (1, 1, 1), padding=\"same\")(out)\n",
    "    # out = tf.keras.activations.relu(out)\n",
    "    out = tf.keras.activations.sigmoid(out)  #! mod\n",
    "    out = out * s\n",
    "    # out = tf.keras.layers.BatchNormalization()(out) #! mod\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def decoder_block(input, filters, concat_layer):\n",
    "    # Upsample the feature maps\n",
    "    x = tf.keras.layers.Conv3DTranspose(\n",
    "        filters, (2, 2, 2), strides=(2, 2, 2), padding=\"same\"\n",
    "    )(input)\n",
    "    concat_layer = attention_gate(x, concat_layer, filters)\n",
    "    x = tf.keras.layers.concatenate(\n",
    "        [x, concat_layer]\n",
    "    )  # Concatenation/Skip conncetion with conjugate encoder\n",
    "    x = conv_block(x, filters)  # Passed into the convolution block above\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    input_shape = (64, 256, 256, 1)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    # normalized_inputs = normalization_layer(inputs)\n",
    "    d1, p1 = encoder_block(inputs, 64)\n",
    "    d2, p2 = encoder_block(p1, 128)\n",
    "    d3, p3 = encoder_block(p2, 256)\n",
    "    d4, p4 = encoder_block(p3, 512)\n",
    "    mid = conv_block(p4, 1024)  # Midsection\n",
    "    e2 = decoder_block(mid, 512, d4)  # Conjugate of encoder 4\n",
    "    e3 = decoder_block(e2, 256, d3)  # Conjugate of encoder 3\n",
    "    e4 = decoder_block(e3, 128, d2)  # Conjugate of encoder 2\n",
    "    e5 = decoder_block(e4, 64, d1)  # Conjugate of encoder 1\n",
    "    outputs = tf.keras.layers.Conv3D(1, (1, 1, 1), activation=\"sigmoid\")(\n",
    "        e5\n",
    "    )  # Final Output\n",
    "    ml = tf.keras.Model(inputs=[inputs], outputs=outputs, name=\"Unet\")\n",
    "    return ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.keras.saving.register_keras_serializable(name=\"adamw\")\n",
    "def opt_adamw():\n",
    "    return tf.keras.optimizers.AdamW(\n",
    "        learning_rate=0.001,\n",
    "        weight_decay=0.004,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07,\n",
    "        amsgrad=False,\n",
    "        clipnorm=None,\n",
    "        clipvalue=None,\n",
    "        global_clipnorm=None,\n",
    "        use_ema=True,\n",
    "        ema_momentum=0.75,\n",
    "        jit_compile=True,\n",
    "        name=\"AdamW\",\n",
    "    )\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "model.compile(\n",
    "    optimizer=opt_adamw(), loss=focal_tversky_loss(), metrics=[dice_coefficient()]\n",
    ")\n",
    "# model.summary()\n",
    "# tf.keras.utils.plot_model(model, to_file='model_3dunet.png', show_shapes=True, show_dtype=False, show_layer_names=True, expand_nested=False, dpi=70,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"1to1ds_batch1_adamw0001_ema075\"\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(PROJECT_FOLDER, f\"saved_models/{MODEL_NAME}.keras\"),\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.CSVLogger(\n",
    "        os.path.join(PROJECT_FOLDER, f\"logs/{MODEL_NAME}.csv\")\n",
    "    ),\n",
    "    tf.keras.callbacks.TerminateOnNaN(),\n",
    "    # tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "    model_checkpoint_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_report(history):\n",
    "    epochs = range(1, 151)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "    # Plot and label the training and validation loss values\n",
    "    ax[0].plot(epochs, history.history[\"loss\"], label=\"Training Loss\")\n",
    "    ax[0].plot(epochs, history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "\n",
    "    # Add in a title and axes labels\n",
    "    ax[0].set_title(\"FOCAL TVERSKY LOSS\")\n",
    "    ax[0].set_xlabel(\"Epochs\")\n",
    "    ax[0].set_ylabel(\"Loss\")\n",
    "\n",
    "    # Set the tick locations\n",
    "    ax[0].set_xticks(np.arange(1, 151, 10))\n",
    "\n",
    "    # Display the plot\n",
    "    ax[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot and label the training and validation TI values\n",
    "    ax[1].plot(epochs, history.history[\"tversky_index\"], label=\"Training TI\")\n",
    "    ax[1].plot(epochs, history.history[\"val_tversky_index\"], label=\"Validation TI\")\n",
    "\n",
    "    # Add in a title and axes labels\n",
    "    ax[1].set_title(\"TVERSKY INDEX\")\n",
    "    ax[1].set_xlabel(\"Epochs\")\n",
    "    ax[1].set_ylabel(\"TI\")\n",
    "\n",
    "    # Set the tick locations\n",
    "    ax[1].set_xticks(np.arange(1, 151, 10))\n",
    "\n",
    "    # Display the plot\n",
    "    ax[1].legend(loc=\"best\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def overlay_images(x, y, y_pred):\n",
    "    mid_slice = int(np.round(x.shape[1] / 2))\n",
    "    ti = TverskyIndex()\n",
    "\n",
    "    x_slice = x[:, mid_slice, :, :, :]\n",
    "    y_slice = y[:, mid_slice, :, :, :]\n",
    "    y_pred_slice = y_pred[:, mid_slice, :, :, :]\n",
    "    ti.update_state(y_slice, y_pred_slice)\n",
    "\n",
    "    x_slice = np.squeeze(x_slice)\n",
    "    y_slice = np.squeeze(y_slice)\n",
    "    y_pred_slice = np.squeeze(y_pred_slice)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "    ax[0].imshow(x_slice, cmap=\"bone\", interpolation=\"none\")\n",
    "    ax[0].imshow(y_slice, cmap=\"jet\", alpha=(0.5 * y_slice))\n",
    "    ax[1].imshow(x_slice, cmap=\"bone\", interpolation=\"none\")\n",
    "    ax[1].imshow(y_pred_slice, cmap=\"jet\", alpha=(0.5 * y_pred_slice))\n",
    "\n",
    "    plt.title(f\"Slice: {mid_slice}. Tversky Index: {ti.result().numpy()} \")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_3d(\n",
    "    images,\n",
    "    labels=[\"Y True\", \"Y Pred\"],\n",
    "    colors=[[0.5, 0.5, 1], [0.9, 0.1, 0.9]],\n",
    "    alpha=[0.5, 0.5],\n",
    "    threshold=[0, 0],\n",
    "):\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    patches = []\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        # Расположим сканирование вертикально,\n",
    "        # так чтобы голова пациента была вверху, лицом к камере\n",
    "        image = image.transpose(2, 0, 1)\n",
    "        image = image[:, :, ::-1]\n",
    "\n",
    "        if idx == 0:\n",
    "            # Устанавливаем границы для каждой оси в соответствии с формой транспонированного изображения\n",
    "            ax.set_xlim(0, image.shape[0])\n",
    "            ax.set_ylim(0, image.shape[1])\n",
    "            ax.set_zlim(0, image.shape[2])\n",
    "\n",
    "        # Получаем вершины и грани 3D модели, используя marching_cubes\n",
    "        verts, faces, _, _ = measure.marching_cubes(image, threshold[idx])\n",
    "        # Создаем объект Figure в matplotlib и добавляем в него 3D подзаголовок\n",
    "\n",
    "        # Создаем коллекцию треугольников из вершин и граней, устанавливаем цвет и прозрачность, добавляем в подзаголовок\n",
    "        mesh = Poly3DCollection(verts[faces], alpha=alpha[idx])\n",
    "        face_color = colors[idx]\n",
    "        mesh.set_facecolor(face_color)\n",
    "        ax.add_collection3d(mesh)\n",
    "        patches.append(mpatches.Patch(color=colors[idx], label=labels[idx]))\n",
    "    ax.legend(handles=patches)\n",
    "\n",
    "    # Отображаем визуализацию\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_results(model, dataset):\n",
    "    VOXELS_THRESHOLD = 30\n",
    "    ftl = FocalTverskyLoss()\n",
    "    correct_predictions = [0]\n",
    "    for x, y, *z in dataset:\n",
    "        ti = TverskyIndex()\n",
    "        y_pred, _ = model.predict(x)\n",
    "        y_pred = tf.where(y_pred >= 0.5, 1.0, 0.0)\n",
    "        loss = ftl(tf.cast(y, dtype=tf.float32), y_pred)\n",
    "        ti.update_state(tf.cast(y, dtype=tf.float32), y_pred)\n",
    "        overlay_images(x, y, y_pred)\n",
    "        print(\"\\n\\n\")\n",
    "        x = tf.squeeze(x).numpy()\n",
    "        y = tf.squeeze(y).numpy()\n",
    "        y_pred = tf.squeeze(y_pred).numpy()\n",
    "        print(\"FocalTverskyLoss:\", loss.numpy(), \"| TverskyIndex:\", ti.result().numpy())\n",
    "        if np.max(y) > 0:\n",
    "            if np.max(y_pred) > 0 and np.count_nonzero(y_pred) > VOXELS_THRESHOLD:\n",
    "                print(\n",
    "                    f\"CORRECT:  Existing effusion event FOUND: {np.count_nonzero(y)}/{np.count_nonzero(y_pred)} voxels\"\n",
    "                )\n",
    "                correct_predictions[0] += 1\n",
    "                plot_3d([y, y_pred])\n",
    "            else:\n",
    "                print(\n",
    "                    f\"INCORRECT:  Existing effusion event NOT FOUND: {np.count_nonzero(y)}/{np.count_nonzero(y_pred)} voxels\"\n",
    "                )\n",
    "                plot_3d([y], labels=[\"Y_TRUE\"])\n",
    "        else:\n",
    "            if np.max(y_pred) > 0 and np.count_nonzero(y_pred) > VOXELS_THRESHOLD:\n",
    "                print(\n",
    "                    f\"INCORRECT:  Non-existing effusion event FOUND +: {np.count_nonzero(y)}/{np.count_nonzero(y_pred)} voxels\"\n",
    "                )\n",
    "                plot_3d([y_pred], labels=[\"Y_PRED\"])\n",
    "            else:\n",
    "                print(\n",
    "                    f\"CORRECT: Non-existing effusion event NOT FOUND -: {np.count_nonzero(y)}/{np.count_nonzero(y_pred)} voxels\"\n",
    "                )\n",
    "                correct_predictions[0] += 1\n",
    "\n",
    "        print(\"\\n \\n\")\n",
    "    print(\n",
    "        f\"TOTAL CORRECT PREDICTIONS (with threshold of {VOXELS_THRESHOLD} voxels): {correct_predictions[0]}/10\"\n",
    "    )\n",
    "    print(\"\\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds, verbose=2)\n",
    "print(\"\\n\\n\")\n",
    "plot_train_report(history)\n",
    "print(\"\\n\\n\")\n",
    "plot_results(model, test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
