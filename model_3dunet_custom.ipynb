{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# for colab\n",
    "%pip install tensorflow==2.13\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.13.0\n",
      "Python Platform: macOS-13.4.1-arm64-arm-64bit\n",
      "Python 3.11.4 (v3.11.4:d2340ef257, Jun  6 2023, 19:15:51) [Clang 13.0.0 (clang-1300.0.29.30)]\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#import gc\n",
    "#from google.colab import drive\n",
    "from skimage import measure\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib.patches as mpatches\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import sys, os, platform\n",
    "\n",
    "print('Tensorflow version:',tf.__version__)\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Python {sys.version}\")\n",
    "gpu = len(tf.config.list_physical_devices(\"GPU\")) > 0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SLICES = 192\n",
    "DIMENSION = 256\n",
    "PROJECT_FOLDER = \"/Users/dutking/LOCAL/AI_uni/radlogix\"  # \"/content/drive/MyDrive/Dmitrii_Utkin/model_3dunet_custom\"\n",
    "DS_FOLDER = \"dataset/tfrecords_1to1_deep_supervision\"  # dataset\n",
    "TRAIN_DS_FILE = \"train.tfrecords\"\n",
    "VAL_DS_FILE = \"val.tfrecords\"\n",
    "TEST_DS_FILE = \"test.tfrecords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_train_record(record):\n",
    "    name_to_features = {\n",
    "        \"shape\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"feature\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"mini_label\": tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    return tf.io.parse_single_example(record, name_to_features)\n",
    "\n",
    "\n",
    "def decode_train_record(record):\n",
    "    feature = tf.io.decode_raw(\n",
    "        record[\"feature\"],\n",
    "        out_type=\"float64\",\n",
    "        little_endian=True,\n",
    "        fixed_length=None,\n",
    "        name=None,\n",
    "    )\n",
    "    label = tf.io.decode_raw(\n",
    "        record[\"label\"],\n",
    "        out_type=\"int16\",\n",
    "        little_endian=True,\n",
    "        fixed_length=None,\n",
    "        name=None,\n",
    "    )\n",
    "    shape = tf.io.decode_raw(\n",
    "        record[\"shape\"],\n",
    "        out_type=\"int64\",\n",
    "        little_endian=True,\n",
    "        fixed_length=None,\n",
    "        name=None,\n",
    "    )\n",
    "    mini_label = tf.io.decode_raw(\n",
    "        record[\"mini_label\"],\n",
    "        out_type=\"int16\",\n",
    "        little_endian=True,\n",
    "        fixed_length=None,\n",
    "        name=None,\n",
    "    )\n",
    "    label = tf.cast(tf.reshape(label, shape), dtype=tf.float32)\n",
    "    feature = tf.cast(tf.reshape(feature, shape), dtype=tf.float32)\n",
    "    mini_label = tf.cast(\n",
    "        tf.reshape(\n",
    "            mini_label,\n",
    "            (int(TARGET_SLICES / 2), int(DIMENSION / 2), int(DIMENSION / 2), 1),\n",
    "        ),\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "    label.set_shape((TARGET_SLICES, DIMENSION, DIMENSION, 1))\n",
    "    feature.set_shape((TARGET_SLICES, DIMENSION, DIMENSION, 1))\n",
    "    mini_label.set_shape(\n",
    "        (int(TARGET_SLICES / 2), int(DIMENSION / 2), int(DIMENSION / 2), 1)\n",
    "    )\n",
    "    return (feature, label, mini_label)\n",
    "\n",
    "\n",
    "def parse_record(record):\n",
    "    name_to_features = {\n",
    "        \"shape\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"feature\": tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    return tf.io.parse_single_example(record, name_to_features)\n",
    "\n",
    "\n",
    "def decode_record(record):\n",
    "    feature = tf.io.decode_raw(\n",
    "        record[\"feature\"],\n",
    "        out_type=\"float64\",\n",
    "        little_endian=True,\n",
    "        fixed_length=None,\n",
    "        name=None,\n",
    "    )\n",
    "    label = tf.io.decode_raw(\n",
    "        record[\"label\"],\n",
    "        out_type=\"int16\",\n",
    "        little_endian=True,\n",
    "        fixed_length=None,\n",
    "        name=None,\n",
    "    )\n",
    "    shape = tf.io.decode_raw(\n",
    "        record[\"shape\"],\n",
    "        out_type=\"int64\",\n",
    "        little_endian=True,\n",
    "        fixed_length=None,\n",
    "        name=None,\n",
    "    )\n",
    "    label = tf.cast(tf.reshape(label, shape), dtype=tf.float32)\n",
    "    feature = tf.cast(tf.reshape(feature, shape), dtype=tf.float64)\n",
    "    label.set_shape((TARGET_SLICES, DIMENSION, DIMENSION, 1))\n",
    "    feature.set_shape((TARGET_SLICES, DIMENSION, DIMENSION, 1))\n",
    "    return (feature, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"CPU\"):\n",
    "    train_ds = (\n",
    "        tf.data.TFRecordDataset(\n",
    "            os.path.join(PROJECT_FOLDER, DS_FOLDER, TRAIN_DS_FILE),\n",
    "            compression_type=\"GZIP\",\n",
    "        )\n",
    "        .map(parse_train_record, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .map(decode_train_record, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    # norm_ds = train_ds.map(lambda x, y, z: x)\n",
    "    # normalization_layer = tf.keras.layers.Normalization(axis=None)\n",
    "    # normalization_layer.adapt(norm_ds)\n",
    "    # del norm_ds\n",
    "\n",
    "    train_ds = (\n",
    "        train_ds.cache()\n",
    "        .shuffle(74, reshuffle_each_iteration=False)  # train_ds.cardinality().numpy()\n",
    "        .batch(1)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    val_ds = (\n",
    "        tf.data.TFRecordDataset(\n",
    "            os.path.join(PROJECT_FOLDER, DS_FOLDER, VAL_DS_FILE),\n",
    "            compression_type=\"GZIP\",\n",
    "        )\n",
    "        .map(parse_record, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .map(decode_record, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    )\n",
    "    val_ds = (\n",
    "        val_ds.cache()\n",
    "        .shuffle(20, reshuffle_each_iteration=False)\n",
    "        .batch(1)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    test_ds = (\n",
    "        tf.data.TFRecordDataset(\n",
    "            os.path.join(PROJECT_FOLDER, DS_FOLDER, TEST_DS_FILE),\n",
    "            compression_type=\"GZIP\",\n",
    "        )\n",
    "        .map(parse_record, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .map(decode_record, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .cache()\n",
    "        .batch(1)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Unet3D\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_20 (InputLayer)       [(None, 192, 256, 256, 1)]   0         []                            \n",
      "                                                                                                  \n",
      " conv3d_342 (Conv3D)         (None, 192, 256, 256, 1)     28        ['input_20[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_343 (Conv3D)         (None, 192, 256, 256, 1)     28        ['conv3d_342[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_171 (B  (None, 192, 256, 256, 1)     4         ['conv3d_343[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.nn.relu_171 (TFOpLambda  (None, 192, 256, 256, 1)     0         ['batch_normalization_171[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling3d_76 (MaxPooli  (None, 96, 128, 128, 1)      0         ['tf.nn.relu_171[0][0]']      \n",
      " ng3D)                                                                                            \n",
      "                                                                                                  \n",
      " conv3d_344 (Conv3D)         (None, 96, 128, 128, 1)      28        ['max_pooling3d_76[0][0]']    \n",
      "                                                                                                  \n",
      " conv3d_345 (Conv3D)         (None, 96, 128, 128, 1)      28        ['conv3d_344[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_172 (B  (None, 96, 128, 128, 1)      4         ['conv3d_345[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.nn.relu_172 (TFOpLambda  (None, 96, 128, 128, 1)      0         ['batch_normalization_172[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling3d_77 (MaxPooli  (None, 48, 64, 64, 1)        0         ['tf.nn.relu_172[0][0]']      \n",
      " ng3D)                                                                                            \n",
      "                                                                                                  \n",
      " conv3d_346 (Conv3D)         (None, 48, 64, 64, 1)        28        ['max_pooling3d_77[0][0]']    \n",
      "                                                                                                  \n",
      " conv3d_347 (Conv3D)         (None, 48, 64, 64, 1)        28        ['conv3d_346[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_173 (B  (None, 48, 64, 64, 1)        4         ['conv3d_347[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.nn.relu_173 (TFOpLambda  (None, 48, 64, 64, 1)        0         ['batch_normalization_173[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling3d_78 (MaxPooli  (None, 24, 32, 32, 1)        0         ['tf.nn.relu_173[0][0]']      \n",
      " ng3D)                                                                                            \n",
      "                                                                                                  \n",
      " conv3d_348 (Conv3D)         (None, 24, 32, 32, 1)        28        ['max_pooling3d_78[0][0]']    \n",
      "                                                                                                  \n",
      " conv3d_349 (Conv3D)         (None, 24, 32, 32, 1)        28        ['conv3d_348[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_174 (B  (None, 24, 32, 32, 1)        4         ['conv3d_349[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.nn.relu_174 (TFOpLambda  (None, 24, 32, 32, 1)        0         ['batch_normalization_174[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling3d_79 (MaxPooli  (None, 12, 16, 16, 1)        0         ['tf.nn.relu_174[0][0]']      \n",
      " ng3D)                                                                                            \n",
      "                                                                                                  \n",
      " conv3d_350 (Conv3D)         (None, 12, 16, 16, 1)        28        ['max_pooling3d_79[0][0]']    \n",
      "                                                                                                  \n",
      " conv3d_351 (Conv3D)         (None, 12, 16, 16, 1)        28        ['conv3d_350[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_175 (B  (None, 12, 16, 16, 1)        4         ['conv3d_351[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.nn.relu_175 (TFOpLambda  (None, 12, 16, 16, 1)        0         ['batch_normalization_175[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv3d_transpose_76 (Conv3  (None, 24, 32, 32, 1)        9         ['tf.nn.relu_175[0][0]']      \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate_76 (Concatenat  (None, 24, 32, 32, 2)        0         ['conv3d_transpose_76[0][0]', \n",
      " e)                                                                  'tf.nn.relu_174[0][0]']      \n",
      "                                                                                                  \n",
      " conv3d_352 (Conv3D)         (None, 24, 32, 32, 1)        55        ['concatenate_76[0][0]']      \n",
      "                                                                                                  \n",
      " conv3d_353 (Conv3D)         (None, 24, 32, 32, 1)        28        ['conv3d_352[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_176 (B  (None, 24, 32, 32, 1)        4         ['conv3d_353[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.nn.relu_176 (TFOpLambda  (None, 24, 32, 32, 1)        0         ['batch_normalization_176[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv3d_transpose_77 (Conv3  (None, 48, 64, 64, 1)        9         ['tf.nn.relu_176[0][0]']      \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate_77 (Concatenat  (None, 48, 64, 64, 2)        0         ['conv3d_transpose_77[0][0]', \n",
      " e)                                                                  'tf.nn.relu_173[0][0]']      \n",
      "                                                                                                  \n",
      " conv3d_354 (Conv3D)         (None, 48, 64, 64, 1)        55        ['concatenate_77[0][0]']      \n",
      "                                                                                                  \n",
      " conv3d_355 (Conv3D)         (None, 48, 64, 64, 1)        28        ['conv3d_354[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_177 (B  (None, 48, 64, 64, 1)        4         ['conv3d_355[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.nn.relu_177 (TFOpLambda  (None, 48, 64, 64, 1)        0         ['batch_normalization_177[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv3d_transpose_78 (Conv3  (None, 96, 128, 128, 1)      9         ['tf.nn.relu_177[0][0]']      \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate_78 (Concatenat  (None, 96, 128, 128, 2)      0         ['conv3d_transpose_78[0][0]', \n",
      " e)                                                                  'tf.nn.relu_172[0][0]']      \n",
      "                                                                                                  \n",
      " conv3d_356 (Conv3D)         (None, 96, 128, 128, 1)      55        ['concatenate_78[0][0]']      \n",
      "                                                                                                  \n",
      " conv3d_357 (Conv3D)         (None, 96, 128, 128, 1)      28        ['conv3d_356[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_178 (B  (None, 96, 128, 128, 1)      4         ['conv3d_357[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.nn.relu_178 (TFOpLambda  (None, 96, 128, 128, 1)      0         ['batch_normalization_178[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv3d_transpose_79 (Conv3  (None, 192, 256, 256, 1)     9         ['tf.nn.relu_178[0][0]']      \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate_79 (Concatenat  (None, 192, 256, 256, 2)     0         ['conv3d_transpose_79[0][0]', \n",
      " e)                                                                  'tf.nn.relu_171[0][0]']      \n",
      "                                                                                                  \n",
      " conv3d_358 (Conv3D)         (None, 192, 256, 256, 1)     55        ['concatenate_79[0][0]']      \n",
      "                                                                                                  \n",
      " conv3d_359 (Conv3D)         (None, 192, 256, 256, 1)     28        ['conv3d_358[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_179 (B  (None, 192, 256, 256, 1)     4         ['conv3d_359[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.nn.relu_179 (TFOpLambda  (None, 192, 256, 256, 1)     0         ['batch_normalization_179[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " finalOutput (Conv3D)        (None, 192, 256, 256, 1)     2         ['tf.nn.relu_179[0][0]']      \n",
      "                                                                                                  \n",
      " preOutput (Conv3D)          (None, 96, 128, 128, 1)      2         ['tf.nn.relu_178[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 692 (2.70 KB)\n",
      "Trainable params: 670 (2.62 KB)\n",
      "Non-trainable params: 22 (88.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.saving.get_custom_objects().clear()\n",
    "\n",
    "\n",
    "@tf.keras.saving.register_keras_serializable(name=\"tversky_index\")\n",
    "class TverskyIndex(tf.keras.metrics.Metric):\n",
    "    def __init__(self, delta=0.5, smooth=0.000001, name=\"tversky_index\", **kwargs):\n",
    "        super(TverskyIndex, self).__init__(name=name, **kwargs)\n",
    "        self.ti = self.add_weight(name=\"ti\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(name=\"ti_c\", initializer=\"zeros\")\n",
    "        self.delta = delta\n",
    "        self.smooth = smooth\n",
    "\n",
    "    @tf.function\n",
    "    def identify_axis(self, shape):\n",
    "        # Three dimensional\n",
    "        if len(shape) == 5:\n",
    "            return [1, 2, 3]\n",
    "        # Two dimensional\n",
    "        elif len(shape) == 4:\n",
    "            return [1, 2]\n",
    "        # Exception - Unknown\n",
    "        else:\n",
    "            raise ValueError(\"Metric: Shape of tensor is neither 2D or 3D.\")\n",
    "\n",
    "    @tf.function\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        axis = self.identify_axis(y_true.get_shape())\n",
    "        y_pred = tf.where(y_pred >= 0.5, 1.0, 0.0)  # MY\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)\n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1 - y_pred), axis=axis)\n",
    "        fp = K.sum((1 - y_true) * y_pred, axis=axis)\n",
    "        ti_class = (tp + self.smooth) / (\n",
    "            tp + self.delta * fn + (1 - self.delta) * fp + self.smooth\n",
    "        )\n",
    "        # Average class scores\n",
    "        ti = K.mean(ti_class)\n",
    "        self.ti.assign_add(ti)\n",
    "        self.count.assign_add(1.0)\n",
    "\n",
    "    def result(self):\n",
    "        if self.count == 0.0:\n",
    "            return self.ti\n",
    "\n",
    "        mean_ti = self.ti / self.count\n",
    "        return mean_ti\n",
    "\n",
    "    def reset_state(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.count.assign(0.0)\n",
    "        self.ti.assign(0.0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"delta\": self.delta, \"smooth\": self.smooth}\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}\n",
    "\n",
    "\n",
    "@tf.keras.saving.register_keras_serializable(name=\"focal_tversky_loss\")\n",
    "class FocalTverskyLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, delta=0.7, gamma=0.75, smooth=0.000001, name=\"ftl\", **kwargs):\n",
    "        super(FocalTverskyLoss, self).__init__(name=name, **kwargs)\n",
    "        self.delta = delta\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "\n",
    "    @tf.function\n",
    "    def identify_axis(self, shape):\n",
    "        # Three dimensional\n",
    "        if len(shape) == 5:\n",
    "            return [1, 2, 3]\n",
    "        # Two dimensional\n",
    "        elif len(shape) == 4:\n",
    "            return [1, 2]\n",
    "        # Exception - Unknown\n",
    "        else:\n",
    "            raise ValueError(\"Metric: Shape of tensor is neither 2D or 3D.\")\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        axis = self.identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)\n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1 - y_pred), axis=axis)\n",
    "        fp = K.sum((1 - y_true) * y_pred, axis=axis)\n",
    "\n",
    "        tversky_class = (tp + self.smooth) / (\n",
    "            tp + self.delta * fn + (1 - self.delta) * fp + self.smooth\n",
    "        )\n",
    "        # Average class scores\n",
    "        ftl = K.mean(K.pow((1 - tversky_class), self.gamma))\n",
    "        return ftl\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"delta\": self.delta, \"gamma\": self.gamma, \"smooth\": self.smooth}\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}\n",
    "\n",
    "\n",
    "@tf.keras.saving.register_keras_serializable(name=\"ModelUnet3d\")\n",
    "class ModelUnet3d(tf.keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ModelUnet3d, self).__init__(*args, **kwargs)\n",
    "        self.loss_weights = [1.0, 0.5]\n",
    "        self.ti_metric = TverskyIndex()\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y, z = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_preds = self(x, training=True)\n",
    "            if type(y_preds) == list:\n",
    "                y_pred, z_pred = y_preds\n",
    "                loss = self.loss_weights[0] * self.compute_loss(y=y, y_pred=y_pred)\n",
    "                loss += self.loss_weights[1] * self.compute_loss(\n",
    "                    y=z, y_pred=z_pred\n",
    "                )  # Deep Supervision Loss\n",
    "                for metric in self.metrics:\n",
    "                    if metric.name == \"loss\":\n",
    "                        metric.update_state(loss)\n",
    "                    else:\n",
    "                        metric.update_state(y, y_preds[0])\n",
    "            else:\n",
    "                loss = self.compute_loss(y=y, y_pred=y_preds)\n",
    "                for metric in self.metrics:\n",
    "                    if metric.name == \"loss\":\n",
    "                        metric.update_state(loss)\n",
    "                    else:\n",
    "                        metric.update_state(y, y_preds)\n",
    "        trainable_vars = self.trainable_variables  # Network trainable parameters\n",
    "        gradients = tape.gradient(loss, trainable_vars)  # Calculating gradients\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, trainable_vars)\n",
    "        )  # Applying gradients to optimizer\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred, _ = self(x, training=False)\n",
    "        loss = self.compute_loss(y=y, y_pred=y_pred)\n",
    "        # loss = self.loss_fn(y, y_pred)\n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(y, y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"inputs\": self.inputs,\n",
    "            \"ti_metric\": self.ti_metric,\n",
    "            \"loss_tracker\": self.loss_tracker,\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        inputs_config = config.pop(\"inputs\")\n",
    "        inputs = keras.saving.deserialize_keras_object(inputs_config)\n",
    "        ti_metric_config = config.pop(\"ti_metric\")\n",
    "        ti_metric = keras.saving.deserialize_keras_object(ti_metric_config)\n",
    "        loss_tracker_config = config.pop(\"loss_tracker\")\n",
    "        loss_tracker = keras.saving.deserialize_keras_object(loss_tracker_config)\n",
    "        return cls(inputs, ti_metric, loss_tracker, **config)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "        return [self.loss_tracker, self.ti_metric]  #\n",
    "\n",
    "\n",
    "def conv_block(inputs, filters, activation=\"relu\", kernel_initializer=\"he_normal\"):\n",
    "    \"\"\"\n",
    "    Convolution block of a UNet encoder\n",
    "    \"\"\"\n",
    "    x = tf.keras.layers.Conv3D(\n",
    "        filters,\n",
    "        (3, 3, 3),\n",
    "        padding=\"same\",\n",
    "        activation=activation,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "    )(inputs)\n",
    "    x = tf.keras.layers.Conv3D(\n",
    "        filters,\n",
    "        (3, 3, 3),\n",
    "        padding=\"same\",\n",
    "        activation=activation,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def encoder_block(inputs, filters):\n",
    "    \"\"\"\n",
    "    Encoder block of a UNet passes the result from the convolution block\n",
    "    above to a max pooling layer\n",
    "    \"\"\"\n",
    "    x = conv_block(inputs, filters)\n",
    "    p = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "\n",
    "def decoder_block(inputs, filters, concat_layer):\n",
    "    # Upsample the feature maps\n",
    "    x = tf.keras.layers.Conv3DTranspose(\n",
    "        filters, (2, 2, 2), strides=(2, 2, 2), padding=\"same\"\n",
    "    )(inputs)\n",
    "    x = tf.keras.layers.concatenate(\n",
    "        [x, concat_layer]\n",
    "    )  # Concatenation/Skip conncetion with conjuagte encoder\n",
    "    x = conv_block(x, filters)  # Passed into the convolution block above\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    input_shape = (192, 256, 256, 1)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    # normalized_inputs = normalization_layer(inputs)\n",
    "    d1, p1 = encoder_block(inputs, 1)  # 32\n",
    "    d2, p2 = encoder_block(p1, 1)  # 64\n",
    "    d3, p3 = encoder_block(p2, 1)  # 128\n",
    "    d4, p4 = encoder_block(p3, 1)  # 200\n",
    "    mid = conv_block(p4, 1)  # Midsection 256\n",
    "    e2 = decoder_block(mid, 1, d4)  # Conjugate of encoder 4 - 200\n",
    "    e3 = decoder_block(e2, 1, d3)  # Conjugate of encoder 3 - 128\n",
    "    e4 = decoder_block(e3, 1, d2)  # Conjugate of encoder 2 - 64\n",
    "    o1 = tf.keras.layers.Conv3D(1, (1, 1, 1), activation=\"sigmoid\", name=\"preOutput\")(\n",
    "        e4\n",
    "    )  # Output from 2nd last decoder (32,128,128,1)\n",
    "    e5 = decoder_block(e4, 1, d1)  # Conjugate of encoder 1 - 32\n",
    "    output = tf.keras.layers.Conv3D(\n",
    "        1, (1, 1, 1), activation=\"sigmoid\", name=\"finalOutput\"\n",
    "    )(e5)\n",
    "    ml = ModelUnet3d(inputs=[inputs], outputs=[output, o1], name=\"Unet3D\")\n",
    "    return ml\n",
    "\n",
    "\n",
    "@tf.keras.saving.register_keras_serializable(name=\"adamw\")\n",
    "def opt_adamw():\n",
    "    return tf.keras.optimizers.AdamW(\n",
    "        learning_rate=0.001,\n",
    "        weight_decay=0.004,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07,\n",
    "        amsgrad=False,\n",
    "        clipnorm=None,\n",
    "        clipvalue=None,\n",
    "        global_clipnorm=None,\n",
    "        use_ema=True,\n",
    "        ema_momentum=0.75,\n",
    "        jit_compile=True,\n",
    "        name=\"AdamW\",\n",
    "    )\n",
    "\n",
    "\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.001, epsilon=None, amsgrad=False, beta_1=0.9, beta_2=0.99)\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=opt_adamw(), loss=FocalTverskyLoss())\n",
    "\n",
    "model.summary()\n",
    "# tf.keras.utils.plot_model(model, to_file='model_3dunet.png', show_shapes=True, show_dtype=False, show_layer_names=True, expand_nested=False, dpi=70,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"custom\"\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(PROJECT_FOLDER, f\"saved_models/{MODEL_NAME}.keras\"),\n",
    "    save_weights_only=False,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.CSVLogger(\n",
    "        os.path.join(PROJECT_FOLDER, f\"logs/{MODEL_NAME}.csv\")\n",
    "    ),\n",
    "    tf.keras.callbacks.TerminateOnNaN(),\n",
    "    # tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "    model_checkpoint_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 14:44:34.522731: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 34 of 74\n",
      "2023-08-10 14:44:44.537509: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 68 of 74\n",
      "2023-08-10 14:44:46.323288: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n",
      "2023-08-10 14:44:46.693190: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 24s 24s/step\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "model.predict(train_ds.take(1))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot serialize object KerasTensor(type_spec=TensorSpec(shape=(None, 192, 256, 256, 1), dtype=tf.float32, name='input_19'), name='input_19', description=\"created by layer 'input_19'\") of type <class 'keras.src.engine.keras_tensor.KerasTensor'>. To be serializable, a class must implement the `get_config()` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m saved_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49msave_model(\n\u001b[1;32m      2\u001b[0m     model, os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(PROJECT_FOLDER, \u001b[39m\"\u001b[39;49m\u001b[39msaved_models\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mMODEL_NAME\u001b[39m}\u001b[39;49;00m\u001b[39m.keras\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/saving_api.py:146\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m kwargs:\n\u001b[1;32m    142\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    143\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe following argument(s) are not supported \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwith the native Keras format: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m         )\n\u001b[0;32m--> 146\u001b[0m     saving_lib\u001b[39m.\u001b[39;49msave_model(model, filepath)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39m# Legacy case\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39msave_model(\n\u001b[1;32m    150\u001b[0m         model,\n\u001b[1;32m    151\u001b[0m         filepath,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    155\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:151\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, weights_format)\u001b[0m\n\u001b[1;32m    148\u001b[0m _SAVING_V3_ENABLED\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 151\u001b[0m     serialized_model_dict \u001b[39m=\u001b[39m serialize_keras_object(model)\n\u001b[1;32m    152\u001b[0m config_json \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(serialized_model_dict)\n\u001b[1;32m    153\u001b[0m metadata_json \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(\n\u001b[1;32m    154\u001b[0m     {\n\u001b[1;32m    155\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mkeras_version\u001b[39m\u001b[39m\"\u001b[39m: keras\u001b[39m.\u001b[39m__version__,\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdate_saved\u001b[39m\u001b[39m\"\u001b[39m: datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m@\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    157\u001b[0m     }\n\u001b[1;32m    158\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:231\u001b[0m, in \u001b[0;36mserialize_keras_object\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    215\u001b[0m     ts_config \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m    216\u001b[0m         \u001b[39mmap\u001b[39m(\n\u001b[1;32m    217\u001b[0m             \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mas_list()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m         )\n\u001b[1;32m    222\u001b[0m     )\n\u001b[1;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mclass_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m__typespec__\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mspec_name\u001b[39m\u001b[39m\"\u001b[39m: obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mregistered_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    229\u001b[0m     }\n\u001b[0;32m--> 231\u001b[0m inner_config \u001b[39m=\u001b[39m _get_class_or_fn_config(obj)\n\u001b[1;32m    232\u001b[0m config_with_public_class \u001b[39m=\u001b[39m serialize_with_public_class(\n\u001b[1;32m    233\u001b[0m     obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, inner_config\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    236\u001b[0m \u001b[39m# TODO(nkovela): Add TF ops dispatch handler serialization for\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39m# ops.EagerTensor that contains nested numpy array.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m# Target: NetworkConstructionTest.test_constant_initializer_with_numpy\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:382\u001b[0m, in \u001b[0;36m_get_class_or_fn_config\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    378\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    379\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe `get_config()` method of \u001b[39m\u001b[39m{\u001b[39;00mobj\u001b[39m}\u001b[39;00m\u001b[39m should return \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39ma dict. It returned: \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    381\u001b[0m         )\n\u001b[0;32m--> 382\u001b[0m     \u001b[39mreturn\u001b[39;00m serialize_dict(config)\n\u001b[1;32m    383\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    384\u001b[0m     \u001b[39mreturn\u001b[39;00m object_registration\u001b[39m.\u001b[39mget_registered_name(obj)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:394\u001b[0m, in \u001b[0;36mserialize_dict\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mserialize_dict\u001b[39m(obj):\n\u001b[0;32m--> 394\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: serialize_keras_object(value) \u001b[39mfor\u001b[39;49;00m key, value \u001b[39min\u001b[39;49;00m obj\u001b[39m.\u001b[39;49mitems()}\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:394\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mserialize_dict\u001b[39m(obj):\n\u001b[0;32m--> 394\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: serialize_keras_object(value) \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m obj\u001b[39m.\u001b[39mitems()}\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:159\u001b[0m, in \u001b[0;36mserialize_keras_object\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m--> 159\u001b[0m     config_arr \u001b[39m=\u001b[39m [serialize_keras_object(x) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m obj]\n\u001b[1;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(config_arr) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m config_arr\n\u001b[1;32m    161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:159\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m--> 159\u001b[0m     config_arr \u001b[39m=\u001b[39m [serialize_keras_object(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m obj]\n\u001b[1;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(config_arr) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m config_arr\n\u001b[1;32m    161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:231\u001b[0m, in \u001b[0;36mserialize_keras_object\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    215\u001b[0m     ts_config \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m    216\u001b[0m         \u001b[39mmap\u001b[39m(\n\u001b[1;32m    217\u001b[0m             \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mas_list()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m         )\n\u001b[1;32m    222\u001b[0m     )\n\u001b[1;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mclass_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m__typespec__\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mspec_name\u001b[39m\u001b[39m\"\u001b[39m: obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mregistered_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    229\u001b[0m     }\n\u001b[0;32m--> 231\u001b[0m inner_config \u001b[39m=\u001b[39m _get_class_or_fn_config(obj)\n\u001b[1;32m    232\u001b[0m config_with_public_class \u001b[39m=\u001b[39m serialize_with_public_class(\n\u001b[1;32m    233\u001b[0m     obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, inner_config\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    236\u001b[0m \u001b[39m# TODO(nkovela): Add TF ops dispatch handler serialization for\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39m# ops.EagerTensor that contains nested numpy array.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m# Target: NetworkConstructionTest.test_constant_initializer_with_numpy\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:386\u001b[0m, in \u001b[0;36m_get_class_or_fn_config\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[39mreturn\u001b[39;00m object_registration\u001b[39m.\u001b[39mget_registered_name(obj)\n\u001b[1;32m    385\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    387\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot serialize object \u001b[39m\u001b[39m{\u001b[39;00mobj\u001b[39m}\u001b[39;00m\u001b[39m of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(obj)\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo be serializable, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39ma class must implement the `get_config()` method.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot serialize object KerasTensor(type_spec=TensorSpec(shape=(None, 192, 256, 256, 1), dtype=tf.float32, name='input_19'), name='input_19', description=\"created by layer 'input_19'\") of type <class 'keras.src.engine.keras_tensor.KerasTensor'>. To be serializable, a class must implement the `get_config()` method."
     ]
    }
   ],
   "source": [
    "saved_model = tf.keras.models.save_model(\n",
    "    model, os.path.join(PROJECT_FOLDER, \"saved_models\", f\"{MODEL_NAME}.keras\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unable to revive model from config. When overriding the `get_config()` method, make sure that the returned config contains all items used as arguments in the  constructor to <class '__main__.ModelUnet3d'>, which is the default behavior. You can override this default behavior by defining a `from_config(cls, config)` class method to specify how to create an instance of ModelUnet3d from its config.\n\nReceived config={'name': 'Unet3D', 'trainable': True}\n\nError encountered during deserialization: ModelUnet3d.__init__() missing 2 required positional arguments: 'inputs' and 'outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3244\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   3243\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3244\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig)\n\u001b[1;32m   3245\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: ModelUnet3d.__init__() missing 2 required positional arguments: 'inputs' and 'outputs'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m      2\u001b[0m     os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(PROJECT_FOLDER, \u001b[39m\"\u001b[39;49m\u001b[39msaved_models\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mMODEL_NAME\u001b[39m}\u001b[39;49;00m\u001b[39m.keras\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m best_model\u001b[39m.\u001b[39mevaluate(test_ds, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/saving_api.py:230\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m kwargs:\n\u001b[1;32m    226\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe following argument(s) are not supported \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwith the native Keras format: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m    231\u001b[0m         filepath,\n\u001b[1;32m    232\u001b[0m         custom_objects\u001b[39m=\u001b[39;49mcustom_objects,\n\u001b[1;32m    233\u001b[0m         \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m,\n\u001b[1;32m    234\u001b[0m         safe_mode\u001b[39m=\u001b[39;49msafe_mode,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    237\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m    239\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39mcustom_objects, \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:275\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    272\u001b[0m             asset_store\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    274\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 275\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:240\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 240\u001b[0m     model \u001b[39m=\u001b[39m deserialize_keras_object(\n\u001b[1;32m    241\u001b[0m         config_dict, custom_objects, safe_mode\u001b[39m=\u001b[39;49msafe_mode\n\u001b[1;32m    242\u001b[0m     )\n\u001b[1;32m    244\u001b[0m all_filenames \u001b[39m=\u001b[39m zf\u001b[39m.\u001b[39mnamelist()\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m _VARS_FNAME \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m all_filenames:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:704\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m safe_mode_scope \u001b[39m=\u001b[39m SafeModeScope(safe_mode)\n\u001b[1;32m    703\u001b[0m \u001b[39mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[0;32m--> 704\u001b[0m     instance \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_config(inner_config)\n\u001b[1;32m    705\u001b[0m     build_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbuild_config\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    706\u001b[0m     \u001b[39mif\u001b[39;00m build_config:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3246\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   3244\u001b[0m         model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n\u001b[1;32m   3245\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3246\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   3247\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to revive model from config. When overriding \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3248\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthe `get_config()` method, make sure that the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3249\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mreturned config contains all items used as arguments \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3250\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39min the  constructor to \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3251\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwhich is the default behavior. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou can override this default behavior by defining a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3253\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`from_config(cls, config)` class method to specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3254\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mhow to create an \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3255\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstance of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m from its config.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3256\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived config=\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3257\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError encountered during deserialization: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3258\u001b[0m         )\n\u001b[1;32m   3259\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to revive model from config. When overriding the `get_config()` method, make sure that the returned config contains all items used as arguments in the  constructor to <class '__main__.ModelUnet3d'>, which is the default behavior. You can override this default behavior by defining a `from_config(cls, config)` class method to specify how to create an instance of ModelUnet3d from its config.\n\nReceived config={'name': 'Unet3D', 'trainable': True}\n\nError encountered during deserialization: ModelUnet3d.__init__() missing 2 required positional arguments: 'inputs' and 'outputs'"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\n",
    "    os.path.join(PROJECT_FOLDER, \"saved_models\", f\"{MODEL_NAME}.keras\")\n",
    ")\n",
    "best_model.evaluate(test_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds, validation_data=val_ds, verbose=2, epochs=2, callbacks=callbacks\n",
    ")\n",
    "\n",
    "model.evaluate(test_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_report(history):\n",
    "    epochs = range(1, 131)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "    # Plot and label the training and validation loss values\n",
    "    ax[0].plot(epochs, history.history[\"loss\"], label=\"Training Loss\")\n",
    "    ax[0].plot(epochs, history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "\n",
    "    # Add in a title and axes labels\n",
    "    ax[0].set_title(\"FOCAL TVERSKY LOSS\")\n",
    "    ax[0].set_xlabel(\"Epochs\")\n",
    "    ax[0].set_ylabel(\"Loss\")\n",
    "\n",
    "    # Set the tick locations\n",
    "    ax[0].set_xticks(np.arange(1, 131, 10))\n",
    "\n",
    "    # Display the plot\n",
    "    ax[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot and label the training and validation loss values\n",
    "    ax[1].plot(epochs, history.history[\"tversky_index\"], label=\"Training TI\")\n",
    "    ax[1].plot(epochs, history.history[\"val_tversky_index\"], label=\"Validation TI\")\n",
    "\n",
    "    # Add in a title and axes labels\n",
    "    ax[1].set_title(\"TVERSKY INDEX\")\n",
    "    ax[1].set_xlabel(\"Epochs\")\n",
    "    ax[1].set_ylabel(\"TI\")\n",
    "\n",
    "    # Set the tick locations\n",
    "    ax[1].set_xticks(np.arange(1, 131, 10))\n",
    "\n",
    "    # Display the plot\n",
    "    ax[1].legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def overlay_images(x, y, y_pred):\n",
    "    mid_slice = int(np.round(x.shape[1] / 2))\n",
    "    ti = TverskyIndex()\n",
    "\n",
    "    x_slice = x[:, mid_slice, :, :, :]\n",
    "    y_slice = y[:, mid_slice, :, :, :]\n",
    "    y_pred_slice = y_pred[:, mid_slice, :, :, :]\n",
    "    ti.update_state(y_slice, y_pred_slice)\n",
    "\n",
    "    x_slice = np.squeeze(x_slice)\n",
    "    y_slice = np.squeeze(y_slice)\n",
    "    y_pred_slice = np.squeeze(y_pred_slice)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "    ax[0].imshow(x_slice, cmap=\"bone\", interpolation=\"none\")\n",
    "    ax[0].imshow(y_slice, cmap=\"jet\", alpha=(0.5 * y_slice))\n",
    "    ax[1].imshow(x_slice, cmap=\"bone\", interpolation=\"none\")\n",
    "    ax[1].imshow(y_pred_slice, cmap=\"jet\", alpha=(0.5 * y_pred_slice))\n",
    "\n",
    "    plt.title(f\"Slice: {mid_slice}. Tversky Index: {ti.result().numpy()} \")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_3d(\n",
    "    images,\n",
    "    labels=[\"Y True\", \"Y Pred\"],\n",
    "    colors=[[0.5, 0.5, 1], [0.9, 0.1, 0.9]],\n",
    "    alpha=[0.5, 0.5],\n",
    "    threshold=[0, 0],\n",
    "):\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    patches = []\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        #   ,\n",
    "        #      ,   \n",
    "        image = image.transpose(2, 0, 1)\n",
    "        image = image[:, :, ::-1]\n",
    "\n",
    "        if idx == 0:\n",
    "            #           \n",
    "            ax.set_xlim(0, image.shape[0])\n",
    "            ax.set_ylim(0, image.shape[1])\n",
    "            ax.set_zlim(0, image.shape[2])\n",
    "\n",
    "        #     3D ,  marching_cubes\n",
    "        verts, faces, _, _ = measure.marching_cubes(image, threshold[idx])\n",
    "        #   Figure  matplotlib     3D \n",
    "\n",
    "        #       ,    ,   \n",
    "        mesh = Poly3DCollection(verts[faces], alpha=alpha[idx])\n",
    "        face_color = colors[idx]\n",
    "        mesh.set_facecolor(face_color)\n",
    "        ax.add_collection3d(mesh)\n",
    "        patches.append(mpatches.Patch(color=colors[idx], label=labels[idx]))\n",
    "    ax.legend(handles=patches)\n",
    "\n",
    "    #  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_results(model, dataset):\n",
    "    ftl = FocalTverskyLoss()\n",
    "    for x, y, *z in dataset:\n",
    "        ti = TverskyIndex()\n",
    "        y_pred, _ = model.predict(x)\n",
    "        y_pred = tf.where(y_pred >= 0.5, 1.0, 0.0)\n",
    "        loss = ftl(tf.cast(y, dtype=tf.float32), y_pred)\n",
    "        ti.update_state(tf.cast(y, dtype=tf.float32), y_pred)\n",
    "        overlay_images(x, y, y_pred)\n",
    "        x = tf.squeeze(x).numpy()\n",
    "        y = tf.squeeze(y).numpy()\n",
    "        y_pred = tf.squeeze(y_pred).numpy()\n",
    "        print(\"FocalTverskyLoss:\", loss.numpy(), \"| TverskyIndex:\", ti.result().numpy())\n",
    "        if np.max(y) > 0:\n",
    "            if np.max(y_pred) > 0:\n",
    "                print(\n",
    "                    f\"CORRECT:  Existing effusion event FOUND: {np.count_nonzero(y)}/{np.count_nonzero(y_pred)} voxels\"\n",
    "                )\n",
    "                plot_3d([y, y_pred])\n",
    "            else:\n",
    "                print(\n",
    "                    f\"INCORRECT:  Existing effusion event NOT FOUND: {np.count_nonzero(y)}/{np.count_nonzero(y_pred)} voxels\"\n",
    "                )\n",
    "                plot_3d([y])\n",
    "        else:\n",
    "            if np.max(y_pred) > 0:\n",
    "                print(\n",
    "                    f\"INCORRECT:  Non-existing effusion event FOUND +: {np.count_nonzero(y)}/{np.count_nonzero(y_pred)} voxels\"\n",
    "                )\n",
    "                plot_3d([y_pred])\n",
    "            else:\n",
    "                print(\n",
    "                    f\"CORRECT: Non-existing effusion event NOT FOUND -: {np.count_nonzero(y)}/{np.count_nonzero(y_pred)} voxels\"\n",
    "                )\n",
    "\n",
    "        print(\"===== \\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_report(history)\n",
    "plot_results(model, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(\n",
    "    os.path.join(PROJECT_FOLDER, \"saved_models\", f\"{MODEL_NAME}.keras\")\n",
    ")\n",
    "best_model.evaluate(test_ds, verbose=2)\n",
    "plot_results(best_model, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
