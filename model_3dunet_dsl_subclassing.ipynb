{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D UNET model with deep supervision loss and attention gate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.saving.get_custom_objects().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.saving.register_keras_serializable(name=\"Tversky_Index\")\n",
    "class Tversky_Index(tf.keras.metrics.Metric):\n",
    "    def __init__(\n",
    "        self, alpha=0.5, beta=0.5, smooth=0.000001, name=\"tversky_index\", **kwargs\n",
    "    ):\n",
    "        super(TverskyIndex, self).__init__(name=name, **kwargs)\n",
    "        self.ti = self.add_weight(name=\"ti\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(name=\"ti_c\", initializer=\"zeros\")\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.smooth = smooth\n",
    "\n",
    "    @tf.function\n",
    "    def identify_axis(self, shape):\n",
    "        # Three dimensional\n",
    "        if len(shape) == 5:\n",
    "            return [1, 2, 3]\n",
    "        # Two dimensional\n",
    "        elif len(shape) == 4:\n",
    "            return [1, 2]\n",
    "        # Exception - Unknown\n",
    "        else:\n",
    "            raise ValueError(\"Metric: Shape of tensor is neither 2D or 3D.\")\n",
    "\n",
    "    @tf.function\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        axis = self.identify_axis(y_true.get_shape())\n",
    "        y_pred = tf.where(y_pred >= 0.5, 1.0, 0.0)  # MY\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)\n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1 - y_pred), axis=axis)\n",
    "        fp = K.sum((1 - y_true) * y_pred, axis=axis)\n",
    "        ti_class = (tp + self.smooth) / (\n",
    "            tp + self.alpha * fn + self.beta * fp + self.smooth\n",
    "        )\n",
    "        # Average class scores\n",
    "        ti = K.mean(ti_class)\n",
    "        self.ti.assign_add(ti)\n",
    "        self.count.assign_add(1.0)\n",
    "\n",
    "    def result(self):\n",
    "        if self.count == 0.0:\n",
    "            return self.ti\n",
    "\n",
    "        mean_ti = self.ti / self.count\n",
    "        return mean_ti\n",
    "\n",
    "    def reset_state(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.count.assign(0.0)\n",
    "        self.ti.assign(0.0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"delta\": self.delta, \"smooth\": self.smooth}\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.saving.register_keras_serializable(name=\"Focal_Tversky_Loss\")\n",
    "class Focal_Tversky_Loss(tf.keras.losses.Loss):\n",
    "    def __init__(self, delta=0.7, gamma=0.75, smooth=0.000001, name=\"ftl\", **kwargs):\n",
    "        super(FocalTverskyLoss, self).__init__(name=name, **kwargs)\n",
    "        self.delta = delta\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "\n",
    "    @tf.function\n",
    "    def identify_axis(self, shape):\n",
    "        # Three dimensional\n",
    "        if len(shape) == 5:\n",
    "            return [1, 2, 3]\n",
    "        # Two dimensional\n",
    "        elif len(shape) == 4:\n",
    "            return [1, 2]\n",
    "        # Exception - Unknown\n",
    "        else:\n",
    "            raise ValueError(\"Metric: Shape of tensor is neither 2D or 3D.\")\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        axis = self.identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)\n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1 - y_pred), axis=axis)\n",
    "        fp = K.sum((1 - y_true) * y_pred, axis=axis)\n",
    "\n",
    "        tversky_class = (tp + self.smooth) / (\n",
    "            tp + self.delta * fn + (1 - self.delta) * fp + self.smooth\n",
    "        )\n",
    "        # Average class scores\n",
    "        ftl = K.mean(K.pow((1 - tversky_class), self.gamma))\n",
    "        return ftl\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"delta\": self.delta, \"gamma\": self.gamma, \"smooth\": self.smooth}\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.saving.register_keras_serializable(name=\"Conv_Block\")\n",
    "class Conv_Block(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_filters=1,\n",
    "        dropout=0,\n",
    "        *args,\n",
    "        *kwargs\n",
    "    ):\n",
    "        super(Conv_Block, self).__init__(*args, **kwargs)\n",
    "        self.num_filters = num_filters\n",
    "        self.dropout = dropout\n",
    "        #layers\n",
    "        self.conv1 = tf.keras.layers.Conv3D(num_filters, (3, 3, 3), padding=\"same\", kernel_initializer=\"he_normal\", name=f\"{self.name}__conv1\")\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization(axis=-1, name=f\"{self.name}__bn1\")\n",
    "        self.relu1 = tf.keras.layers.ReLU(name=f\"{self.name}__relu1\")\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv3D(num_filters, (3, 3, 3), padding=\"same\", kernel_initializer=\"he_normal\", name=f\"{self.name}__conv2\")\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization(axis=-1, name=f\"{self.name}__bn2\")\n",
    "        self.relu2 = tf.keras.layers.ReLU(name=f\"{self.name}__relu2\")\n",
    "\n",
    "        if self.dropout > 0:\n",
    "           self.do = tf.keras.layers.Dropout(self.dropout, name=f\"{self.name}__do\")\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        if self.dropout > 0:\n",
    "            x = self.do(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"num_filters\": self.num_filters,\n",
    "            \"dropout\": self.dropout,\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.saving.register_keras_serializable(name=\"Res_Conv_Block\")\n",
    "class Res_Conv_Block(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_filters=1, dropout=0, *args, **kwargs):\n",
    "        super(Res_Conv_Block, self).__init__(*args, **kwargs)\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.dropout = dropout\n",
    "        # layers\n",
    "        self.conv1 = tf.keras.layers.Conv3D(\n",
    "            num_filters,\n",
    "            (3, 3, 3),\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            name=f\"{self.name}_conv1\",\n",
    "        )\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization(axis=-1, name=f\"{self.name}__bn1\")\n",
    "        self.relu1 = tf.keras.layers.ReLU(name=f\"{self.name}__relu1\")\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv3D(\n",
    "            num_filters,\n",
    "            (3, 3, 3),\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            name=f\"{self.name}__conv2\",\n",
    "        )\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization(axis=-1, name=f\"{self.name}__bn2\")\n",
    "\n",
    "        if self.dropout > 0:\n",
    "            self.do = tf.keras.layers.Dropout(self.dropout, name=f\"{self.name}__do\")\n",
    "\n",
    "        self.shortcut_conv = tf.keras.layers.Conv3D(\n",
    "            num_filters,\n",
    "            (1, 1, 1),\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            name=f\"{self.name}__shortcut_conv\",\n",
    "        )\n",
    "        self.shortcut_bn = tf.keras.layers.BatchNormalization(\n",
    "            axis=-1, name=f\"{self.name}_shortcut_bn\"\n",
    "        )\n",
    "\n",
    "        self.add = tf.keras.layers.Add(name=f\"{self.name}__add\")\n",
    "        self.add_relu = tf.keras.layers.ReLU(name=f\"{self.name}__add_relu\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.dropout > 0:\n",
    "            x = self.do(x)\n",
    "        shortcut = self.shortcut_conv(inputs)\n",
    "        shortcut = self.shortcut_bn(shortcut)\n",
    "        add = self.add([x, shortcut])\n",
    "        add = self.add_relu(add)\n",
    "        return add\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"num_filters\": self.num_filters,\n",
    "            \"dropout\": self.dropout,\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.saving.register_keras_serializable(name=\"Encoder\")\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_filters=1, *args, **kwargs):\n",
    "        super(Encoder, self).__init__(*args, **kwargs)\n",
    "        self.num_filters = num_filters\n",
    "        self.id = id\n",
    "        self.name = f\"encoder__{self.id}\"\n",
    "        self.conv_block = Res_Conv_Block(\n",
    "            num_filters=num_filters, dropout=0, name=f\"{self.name}__conv_block\"\n",
    "        )\n",
    "        self.max_pool = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv_block(inputs)\n",
    "        p = self.max_pool(x)\n",
    "        return x, p\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"num_filters\": self.num_filters,\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.saving.register_keras_serializable(name=\"Attention_Gate\")\n",
    "class Attention_Gate(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_filters, apply_out_batch_norm=True, *args, **kwargs):\n",
    "        super(Attention_Gate, self).__init__(*args, **kwargs)\n",
    "        self.num_filters = num_filters\n",
    "        self.activation = activation\n",
    "        self.apply_out_batch_norm = apply_out_batch_norm\n",
    "        self.Wg_conv = tf.keras.layers.Conv3D(\n",
    "            self.num_filters, (1, 1, 1), padding=\"same\", name=f\"{self.name}__wg_conv\"\n",
    "        )\n",
    "        self.Wg_bn = tf.keras.layers.BatchNormalization(name=f\"{self.name}__wg_bn\")\n",
    "        self.Ws_conv = tf.keras.layers.Conv3D(\n",
    "            self.num_filters, (1, 1, 1), padding=\"same\", name=f\"{self.name}__ws_conv\"\n",
    "        )\n",
    "        self.Ws_bn = tf.keras.layers.BatchNormalization(name=f\"{self.name}__ws_bn\")\n",
    "        self.relu = tf.keras.layers.ReLU(name=f\"{self.name}__relu\")\n",
    "        self.out_conv = tf.keras.layers.Conv3D(\n",
    "            self.num_filters, (1, 1, 1), padding=\"same\", name=f\"{self.name}__out_conv\"\n",
    "        )\n",
    "        self.out_batch_norm = tf.keras.layers.BatchNormalization(\n",
    "            name=f\"{self.name}__out_bn\"\n",
    "        )\n",
    "        self.out_activation = tf.keras.activations.sigmoid\n",
    "\n",
    "    def call(self, inputs):\n",
    "        g, s = inputs\n",
    "        Wg = self.Wg_conv(g)\n",
    "        Wg = self.Wg_bn(Wg)\n",
    "\n",
    "        Ws = self.Ws_conv(s)\n",
    "        Ws = self.Ws_bn(Ws)\n",
    "\n",
    "        out = self.relu(Wg + Ws)\n",
    "        out = self.out_conv(out)\n",
    "        out = self.out_activation(out)\n",
    "        out = out * s\n",
    "        if apply_out_batch_norm:\n",
    "            out = self.out_batch_norm(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"num_filters\": self.num_filters,\n",
    "            \"apply_out_batch_norm\": self.apply_out_batch_norm,\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.saving.register_keras_serializable(name=\"Decoder\")\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_filters=1, *args, **kwargs):\n",
    "        super(Decoder, self).__init__(*args, **kwargs)\n",
    "        self.num_filters = num_filters\n",
    "        self.conv_block = Res_Conv_Block(\n",
    "            num_layers=num_layers, dropout=0, name=f\"{self.name}__res_conv_block\"\n",
    "        )\n",
    "        self.transpose = tf.keras.layers.Conv3DTranspose(\n",
    "            filters=num_filters,\n",
    "            kernel_size=(2, 2, 2),\n",
    "            strides=(2, 2, 2),\n",
    "            padding=\"same\",\n",
    "            name=f\"{self.name}__transpose\",\n",
    "        )\n",
    "        self.concat = tf.keras.layers.Concatenate(name=f\"{self.name}__concat\")\n",
    "        self.attention_gate = Attention_Gate(\n",
    "            filters=num_filters, name=f\"{self.name}__att_gate\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, concat_layer = inputs\n",
    "        x = self.transpose(inputs)\n",
    "        concat_layer = self.attention_gate([x, concat_layer])\n",
    "        x = self.concat(x, concat_layer)\n",
    "        x = self.conv_block(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"num_layers\": self.num_layers,\n",
    "            \"num_filters\": self.num_filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"padding\": self.padding,\n",
    "            \"activation\": self.activation,\n",
    "            \"kernel_initializer\": self.kernel_initializer,\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.saving.register_keras_serializable(name=\"Model_Unet_3D_DSL\")\n",
    "class Model_Unet_3D_DSL(tf.keras.Model):\n",
    "    def __init__(self, input_shape, *args, **kwargs):\n",
    "        super(Model_Unet_3D, self).__init__(*args, **kwargs)\n",
    "        self.input_shape = input_shape\n",
    "        self.loss_weights = [1.0, 0.5]\n",
    "        self.dice = Tversky_Index(alpha=0.5, beta=0.5, name=\"dice\")\n",
    "        self.jacard = Tversky_Index(alpha=1, beta=1, name=\"jacard\")\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.build(input_shape)  # TO SETUP INPUT SHAPE\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        encoded_1, pooling_1 = encoder_block(inputs, 1, name=\"enc1\")  # 32\n",
    "        encoded_2, pooling_2 = encoder_block(pooling_1, 1, name=\"enc2\")  # 64\n",
    "        encoded_3, pooling_3 = encoder_block(pooling_2, 1, name=\"enc3\")  # 128\n",
    "        encoded_4, pooling_4 = encoder_block(pooling_3, 1, name=\"enc4\")  # 200\n",
    "        mid = conv_block(pooling_4, 1, name=\"mid\")  # Midsection 256\n",
    "        decoded_1 = decoder_block(\n",
    "            mid, 1, encoded_4, name=\"dec1\"\n",
    "        )  # Conjugate of encoder 4 - 200\n",
    "        decoded_2 = decoder_block(\n",
    "            decoded_1, 1, encoded_3, name=\"dec2\"\n",
    "        )  # Conjugate of encoder 3 - 128\n",
    "        decoded_3 = decoder_block(\n",
    "            decoded_2, 1, encoded_2, name=\"dec3\"\n",
    "        )  # Conjugate of encoder 2 - 64\n",
    "        pre_output = tf.keras.layers.Conv3D(\n",
    "            1, (1, 1, 1), activation=\"sigmoid\", name=\"preOutput\"\n",
    "        )(\n",
    "            decoded_3\n",
    "        )  # Output from 2nd last decoder (32,128,128,1)\n",
    "        decoded_4 = decoder_block(\n",
    "            decoded_3, 1, encoded_1, name=\"dec4\"\n",
    "        )  # Conjugate of encoder 1 - 32\n",
    "        output = tf.keras.layers.Conv3D(\n",
    "            1, (1, 1, 1), activation=\"sigmoid\", name=\"finalOutput\"\n",
    "        )(decoded_4)\n",
    "        return [output, pre_output]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y, z = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_preds = self(x, training=True)\n",
    "            if type(y_preds) == list:\n",
    "                y_pred, z_pred = y_preds\n",
    "                loss = self.loss_weights[0] * self.compute_loss(y=y, y_pred=y_pred)\n",
    "                loss += self.loss_weights[1] * self.compute_loss(\n",
    "                    y=z, y_pred=z_pred\n",
    "                )  # Deep Supervision Loss\n",
    "                for metric in self.metrics:\n",
    "                    if metric.name == \"loss\":\n",
    "                        metric.update_state(loss)\n",
    "                    else:\n",
    "                        metric.update_state(y, y_preds[0])\n",
    "            else:\n",
    "                loss = self.compute_loss(y=y, y_pred=y_preds)\n",
    "                for metric in self.metrics:\n",
    "                    if metric.name == \"loss\":\n",
    "                        metric.update_state(loss)\n",
    "                    else:\n",
    "                        metric.update_state(y, y_preds)\n",
    "        trainable_vars = self.trainable_variables  # Network trainable parameters\n",
    "        gradients = tape.gradient(loss, trainable_vars)  # Calculating gradients\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, trainable_vars)\n",
    "        )  # Applying gradients to optimizer\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred, _ = self(x, training=False)\n",
    "        loss = self.compute_loss(y=y, y_pred=y_pred)\n",
    "        # loss = self.loss_fn(y, y_pred)\n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(y, y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"dice\": self.dice,\n",
    "            \"jacard\": self.jacard,\n",
    "            \"loss_tracker\": self.loss_tracker,\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        dice = config.pop(\"dice\")\n",
    "        dice = tf.keras.saving.deserialize_keras_object(dice_config)\n",
    "        jacard = config.pop(\"jacard\")\n",
    "        jacard = tf.keras.saving.deserialize_keras_object(jacard_config)\n",
    "        loss_tracker = config.pop(\"loss_tracker\")\n",
    "        loss_tracker = tf.keras.saving.deserialize_keras_object(loss_tracker_config)\n",
    "        return cls(dice, jacard, loss_tracker, **config)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "        return [self.loss_tracker, self.dice, self.jacard]  #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
