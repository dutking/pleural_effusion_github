{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alecseiterr/pleural_effusion/blob/main/Dmitrii_Utkin/tf_dataset_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hDZdavcfvnK",
        "outputId": "3578a49b-c00b-483a-f49e-751196cdd6bf"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Information on SimpleITK image drections](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1DICOMOrientImageFilter.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob, json, os, shutil\n",
        "import SimpleITK as sitk # install beforehand\n",
        "from functools import reduce\n",
        "from datetime import datetime\n",
        "import ipywidgets as widgets\n",
        "from enum import Enum\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up path constants\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('RPS', 'RAS'), ('RPI', 'RAI'), ('LPS', 'LAS'), ('LPI', 'LAI')]\n"
          ]
        }
      ],
      "source": [
        "LOCAL_FOLDER = os.path.join(\"/Users\", \"dutking\", \"LOCAL\")\n",
        "PROJECT_FOLDER = os.path.join(LOCAL_FOLDER, \"AI_uni\", \"radlogix\")\n",
        "EFFUSION_PATH = os.path.join(\n",
        "    PROJECT_FOLDER, \"dataset\", \"effusions_052023\"\n",
        ")  # /LUNG1-001/LUNG1-001_effusion_first_reviewer.nii.gz\n",
        "CT_PATH = os.path.join(\n",
        "    PROJECT_FOLDER, \"dataset\", \"features\"\n",
        ")  # /LUNG1-001/09-18-2008-StudyID-NA-69331/0.000000-NA-82046\n",
        "LUNGS_PATH = os.path.join(PROJECT_FOLDER, \"dataset\", \"lungs_labels\")\n",
        "CSV_DF_PATH = os.path.join(\n",
        "    PROJECT_FOLDER,\n",
        "    \"_github\",\n",
        "    \"pleural_effusion\",\n",
        "    \"Dmitrii_Utkin\",\n",
        "    \"_docs\",\n",
        "    \"clean_df_on_latest_ds.csv\",\n",
        ")\n",
        "# INITIAL IMAGES DIRECTIONS IS MESSED UP\n",
        "CT_COORDS = [\"RPS\", \"RPI\", \"LPS\", \"LPI\"]\n",
        "MASK_COORDS = [\"RAS\", \"RAI\", \"LAS\", \"LAI\"]\n",
        "COORDS = list(zip(CT_COORDS, MASK_COORDS))\n",
        "print(COORDS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Target(str, Enum):\n",
        "    CT = \"ct\"\n",
        "    EFFUSION = \"effusion\"\n",
        "    LUNGS = \"lungs\"\n",
        "\n",
        "\n",
        "class Mask(str, Enum):\n",
        "    EFFUSION = \"effusion\"\n",
        "    LUNGS = \"lungs\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name=\"my_model\",\n",
        "        resample_spacing=False,\n",
        "        resample_size=True,\n",
        "        resize_factor=2,\n",
        "        normalize=False,\n",
        "        use_positive_values=False,\n",
        "        crop_values=True,\n",
        "        crop_ranges=[[-1024, 150]],\n",
        "        pad_filler=-1024,\n",
        "        mask=Mask.EFFUSION,\n",
        "        ratio=1 / 1,\n",
        "        coords=COORDS,\n",
        "    ):\n",
        "        self.model_name = model_name\n",
        "        self.resample_spacing = resample_spacing\n",
        "        self.resample_size = resample_size\n",
        "        self.resize_factor = resize_factor\n",
        "        self.normalize = normalize\n",
        "        self.use_positive_values = use_positive_values\n",
        "        self.crop_values = crop_values\n",
        "        self.crop_ranges = crop_ranges\n",
        "        self.pad_filler = pad_filler\n",
        "        self.mask = mask\n",
        "        self.ratio = ratio\n",
        "        self.coords = coords\n",
        "        self.create_folders()\n",
        "        self.set_target_z()\n",
        "        self.set_dimension()\n",
        "\n",
        "    def create_folders(self):\n",
        "        self.model_path = os.path.join(PROJECT_FOLDER, \"models\", self.model_name)\n",
        "        self.dataset_path = os.path.join(self.model_path, \"tfdataset\")\n",
        "        self.logs_path = os.path.join(self.model_path, \"logs\")\n",
        "        self.saved_models_path = os.path.join(self.model_path, \"saved_models\")\n",
        "        if not os.path.exists(self.model_path):\n",
        "            os.makedirs(self.model_path)\n",
        "            os.makedirs(\n",
        "                self.dataset_path,\n",
        "            )\n",
        "            os.makedirs(self.logs_path)\n",
        "            os.makedirs(self.saved_models_path)\n",
        "\n",
        "    def set_target_z(self):\n",
        "        if (\n",
        "            self.resample_spacing and self.resample_size\n",
        "        ):  # resize factor assumed to be 2\n",
        "            self.target_z = 192\n",
        "            return\n",
        "\n",
        "        if self.resample_spacing:\n",
        "            self.target_z = 384\n",
        "            return\n",
        "\n",
        "        if self.resample_size:  # resize factor assumed to be 2\n",
        "            self.target_z = 64\n",
        "            return\n",
        "\n",
        "        self.target_z = 128\n",
        "\n",
        "    def set_dimension(self):\n",
        "        if self.resample_size:  # resize factor assumed to be 2\n",
        "            self.dimension = 256\n",
        "            return\n",
        "\n",
        "        self.dimension = 512\n",
        "\n",
        "    def save_to_JSON(self, suffix=\"\"):\n",
        "        path = os.path.join(self.model_path, \"configs\")\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        with open(os.path.join(path, f\"{self.model_name}{suffix}.json\"), \"w\") as file:\n",
        "            json.dump(self.__dict__, file)\n",
        "\n",
        "    def load_from_JSON(self, filepath):\n",
        "        with open(filepath) as json_file:\n",
        "            data = json.load(json_file)\n",
        "            self.model_name = data.model_name\n",
        "            self.resample_spacing = data.resample_spacing\n",
        "            self.resample_size = data.resample_size\n",
        "            self.resize_factor = data.resize_factor\n",
        "            self.normalize = data.normalize\n",
        "            self.use_positive_values = data.use_positive_values\n",
        "            self.crop_values = data.crop_values\n",
        "            self.crop_ranges = data.crop_ranges\n",
        "            self.pad_filler = data.pad_filler\n",
        "            self.target_z = data.target_z\n",
        "            self.dimension = data.dimension\n",
        "            self.mask = data.mask\n",
        "            self.ratio = data.ratio\n",
        "            self.coords = data.coords\n",
        "            self.create_folders()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_lungs_dfs(use_latest=False):\n",
        "    dfs_path = os.path.join(PROJECT_FOLDER, \"models\", \"lungs_dfs\")\n",
        "    if not os.path.exists(dfs_path):\n",
        "        os.makedirs(dfs_path)\n",
        "\n",
        "    if use_latest:\n",
        "        dfs = glob.glob(f\"{dfs_path}/*.csv\")\n",
        "        if len(dfs) > 0:\n",
        "            restored_dfs = {}\n",
        "            for df in dfs:\n",
        "                name = df.split(\"/\")[-1].split(\"_\")[1]\n",
        "                df = pd.read_csv(df, index_col=\"PatientID\")\n",
        "                df.name = name\n",
        "                restored_dfs[name] = df\n",
        "\n",
        "            return restored_dfs[\"train\"], restored_dfs[\"val\"], restored_dfs[\"test\"]\n",
        "        else:\n",
        "            print(\"No previous dataframes found. Creating new ones...\")\n",
        "\n",
        "    df = pd.read_csv(CSV_DF_PATH, index_col=\"PatientID\")\n",
        "    val_df = df.sample(n=50)\n",
        "    val_df.to_csv(os.path.join(dfs_path, f\"lungs_val_df_{DATE_TIME}.csv\"))\n",
        "    val_df.name = \"val\"\n",
        "    print(\"validation set size:\", len(val_df))\n",
        "    df.drop(val_df.index, inplace=True)\n",
        "\n",
        "    test_df = df.sample(n=25)\n",
        "    test_df.to_csv(os.path.join(dfs_path, f\"lungs_test_df_{DATE_TIME}.csv\"))\n",
        "    test_df.name = \"test\"\n",
        "    print(\"test set size:\", len(test_df))\n",
        "    df.drop(test_df.index, inplace=True)\n",
        "\n",
        "    train_df = df\n",
        "    train_df.to_csv(os.path.join(dfs_path, f\"lungs_train_df_{DATE_TIME}.csv\"))\n",
        "    train_df.name = \"train\"\n",
        "    print(\"train set size:\", len(train_df))\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "\n",
        "def get_effusion_dfs(features_to_labels_ratio=1, use_latest=False):\n",
        "    dfs_path = os.path.join(PROJECT_FOLDER, \"models\", \"dfs\")\n",
        "    if not os.path.exists(dfs_path):\n",
        "        os.makedirs(dfs_path)\n",
        "\n",
        "    if use_latest:\n",
        "        dfs = glob.glob(f\"{dfs_path}/*.csv\")\n",
        "        if len(dfs) > 0:\n",
        "            restored_dfs = {}\n",
        "            for df in dfs:\n",
        "                name = df.split(\"/\")[-1].split(\"_\")[0]\n",
        "                df = pd.read_csv(df, index_col=\"PatientID\")\n",
        "                df.name = name\n",
        "                restored_dfs[name] = df\n",
        "\n",
        "            return restored_dfs[\"train\"], restored_dfs[\"val\"], restored_dfs[\"test\"]\n",
        "        else:\n",
        "            print(\"No previous dataframes found. Creating new ones...\")\n",
        "\n",
        "    df = pd.read_csv(CSV_DF_PATH, index_col=\"PatientID\")\n",
        "    amount_of_effusions = len(df.loc[(df[\"Effusion.Event\"] == 1)])\n",
        "    print(f\"Amount of labels: {amount_of_effusions}\")\n",
        "    print(f\"Amount of features: {len(df)}\")\n",
        "\n",
        "    balanced_df = pd.concat(\n",
        "        [\n",
        "            df.loc[(df[\"Effusion.Event\"] == 1)],\n",
        "            df.loc[(df[\"Effusion.Event\"] == 0)].sample(\n",
        "                n=int(amount_of_effusions * features_to_labels_ratio)\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    balanced_df.to_csv(os.path.join(dfs_path, f\"balanced_df_{DATE_TIME}.csv\"))\n",
        "    print(f\"Balanced df size: {len(balanced_df)}\")\n",
        "\n",
        "    val_df = pd.concat(\n",
        "        [\n",
        "            balanced_df.loc[(balanced_df[\"Effusion.Event\"] == 1)].sample(n=10),\n",
        "            balanced_df.loc[(balanced_df[\"Effusion.Event\"] == 0)].sample(n=10),\n",
        "        ]\n",
        "    )\n",
        "    val_df.to_csv(os.path.join(dfs_path, f\"val_df_{DATE_TIME}.csv\"))\n",
        "    val_df.name = \"val\"\n",
        "    print(\"validation set size:\", len(val_df))\n",
        "    balanced_df.drop(val_df.index, inplace=True)\n",
        "\n",
        "    test_df = pd.concat(\n",
        "        [\n",
        "            balanced_df.loc[(balanced_df[\"Effusion.Event\"] == 1)].sample(n=5),\n",
        "            balanced_df.loc[(balanced_df[\"Effusion.Event\"] == 0)].sample(n=5),\n",
        "        ]\n",
        "    )\n",
        "    test_df.to_csv(os.path.join(dfs_path, f\"test_df_{DATE_TIME}.csv\"))\n",
        "    test_df.name = \"test\"\n",
        "    print(\"test set size:\", len(test_df))\n",
        "    balanced_df.drop(test_df.index, inplace=True)\n",
        "\n",
        "    train_df = balanced_df\n",
        "    train_df.to_csv(os.path.join(dfs_path, f\"train_df_{DATE_TIME}.csv\"))\n",
        "    train_df.name = \"train\"\n",
        "    print(\"train set size:\", len(train_df))\n",
        "    return train_df, val_df, test_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_dicom_folder(id):\n",
        "    for dicom_folder, _, files in os.walk(os.path.join(CT_PATH, id), topdown=False):\n",
        "        if files[0].endswith(\".dcm\"):\n",
        "            return dicom_folder\n",
        "\n",
        "\n",
        "def get_nifti_file(id, path):\n",
        "    if not os.path.exists(os.path.join(path, id)):\n",
        "        return None\n",
        "\n",
        "    file = glob.glob(os.path.join(path, id, \"*.gz\"))[0]\n",
        "    return file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_feature_image(dicom_folder, coord=None):\n",
        "    try:\n",
        "        shutil.rmtree(os.path.join(dicom_folder, \"__MACOSX\"))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    reader = sitk.ImageSeriesReader()\n",
        "    dicom_names = reader.GetGDCMSeriesFileNames(dicom_folder)\n",
        "    reader.SetFileNames(dicom_names)\n",
        "    image = reader.Execute()\n",
        "    # image = sitk.DICOMOrient(image, coord)\n",
        "    return image\n",
        "\n",
        "\n",
        "def get_label_image(file, coord=None):\n",
        "    image = sitk.ReadImage(file)\n",
        "    # image = sitk.DICOMOrient(image, coord)\n",
        "    return image\n",
        "\n",
        "\n",
        "def get_initial_image(target, id):\n",
        "    match target:\n",
        "        case Target.CT:\n",
        "            x = get_dicom_folder(id)\n",
        "            x = get_feature_image(x)\n",
        "            return x\n",
        "        case Target.EFFUSION:\n",
        "            x = get_nifti_file(id, EFFUSION_PATH)\n",
        "            if x is None:\n",
        "                return x\n",
        "            x = sitk.ReadImage(x)\n",
        "            return x\n",
        "        case Target.LUNGS:\n",
        "            x = get_nifti_file(id, LUNGS_PATH)\n",
        "            x = sitk.ReadImage(x)\n",
        "            return x\n",
        "        case _:\n",
        "            return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resample_spacing(image):\n",
        "    resample = sitk.ResampleImageFilter()\n",
        "    resample.SetInterpolator(sitk.sitkLinear)\n",
        "    resample.SetOutputDirection(image.GetDirection())\n",
        "    resample.SetOutputOrigin(image.GetOrigin())\n",
        "    new_spacing = [1, 1, 1]\n",
        "    resample.SetOutputSpacing(new_spacing)\n",
        "\n",
        "    orig_size = np.array(image.GetSize(), dtype=np.int32)\n",
        "    orig_spacing = image.GetSpacing()\n",
        "    new_size = orig_size * (np.array(orig_spacing) / np.array(new_spacing))\n",
        "    new_size = np.ceil(new_size).astype(np.int32)  #  Image dimensions are in integers\n",
        "    new_size = [int(s) for s in new_size]\n",
        "    resample.SetSize(new_size)\n",
        "\n",
        "    new_image = resample.Execute(image)\n",
        "    return new_image\n",
        "\n",
        "\n",
        "def resample_size(patient_CT, resize_factor):\n",
        "    # original_CT = sitk.ReadImage(patient_CT,sitk.sitkInt32)\n",
        "    original_CT = patient_CT\n",
        "    dimension = original_CT.GetDimension()\n",
        "    reference_physical_size = np.zeros(original_CT.GetDimension())\n",
        "    reference_physical_size[:] = [\n",
        "        (sz - 1) * spc if sz * spc > mx else mx\n",
        "        for sz, spc, mx in zip(\n",
        "            original_CT.GetSize(), original_CT.GetSpacing(), reference_physical_size\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    reference_origin = original_CT.GetOrigin()\n",
        "    reference_direction = original_CT.GetDirection()\n",
        "\n",
        "    reference_size = [round(sz / resize_factor) for sz in original_CT.GetSize()]\n",
        "    reference_spacing = [\n",
        "        phys_sz / (sz - 1)\n",
        "        for sz, phys_sz in zip(reference_size, reference_physical_size)\n",
        "    ]\n",
        "\n",
        "    reference_image = sitk.Image(reference_size, original_CT.GetPixelIDValue())\n",
        "    reference_image.SetOrigin(reference_origin)\n",
        "    reference_image.SetSpacing(reference_spacing)\n",
        "    reference_image.SetDirection(reference_direction)\n",
        "\n",
        "    reference_center = np.array(\n",
        "        reference_image.TransformContinuousIndexToPhysicalPoint(\n",
        "            np.array(reference_image.GetSize()) / 2.0\n",
        "        )\n",
        "    )\n",
        "\n",
        "    transform = sitk.AffineTransform(dimension)\n",
        "    transform.SetMatrix(original_CT.GetDirection())\n",
        "\n",
        "    transform.SetTranslation(np.array(original_CT.GetOrigin()) - reference_origin)\n",
        "\n",
        "    centering_transform = sitk.TranslationTransform(dimension)\n",
        "    img_center = np.array(\n",
        "        original_CT.TransformContinuousIndexToPhysicalPoint(\n",
        "            np.array(original_CT.GetSize()) / 2.0\n",
        "        )\n",
        "    )\n",
        "    centering_transform.SetOffset(\n",
        "        np.array(transform.GetInverse().TransformPoint(img_center) - reference_center)\n",
        "    )\n",
        "    centered_transform = sitk.CompositeTransform(transform)\n",
        "    centered_transform.AddTransform(centering_transform)\n",
        "\n",
        "    # sitk.Show(sitk.Resample(original_CT, reference_image, centered_transform, sitk.sitkLinear, 0.0))\n",
        "\n",
        "    return sitk.Resample(\n",
        "        original_CT, reference_image, centered_transform, sitk.sitkLinear, 0.0\n",
        "    )\n",
        "\n",
        "\n",
        "def set_final_size(image, target_slices, dimension, pad_filler):\n",
        "    image_size = image.GetSize()\n",
        "    z = image_size[-1]\n",
        "    z_diff = target_slices - z\n",
        "    if z_diff < 0:\n",
        "        cropped = crop_z(image, np.abs(z_diff))\n",
        "        return pad_xy(cropped, dimension, pad_filler)\n",
        "    elif z_diff > 0:\n",
        "        padded = pad_z(image, np.abs(z_diff), pad_filler)\n",
        "        return pad_xy(padded, dimension, pad_filler)\n",
        "\n",
        "    return pad_xy(image, dimension, pad_filler)\n",
        "\n",
        "\n",
        "def pad_z(image, z_diff, pad_filler):\n",
        "    z_top_pad = int(np.ceil(z_diff / 2))\n",
        "    z_bottom_pad = int(np.floor(z_diff / 2))\n",
        "    padded_image = sitk.ConstantPad(\n",
        "        image, (0, 0, z_bottom_pad), (0, 0, z_top_pad), pad_filler\n",
        "    )\n",
        "    return padded_image\n",
        "\n",
        "\n",
        "def crop_z(image, z_diff):\n",
        "    z_top_crop = int(np.ceil(z_diff / 2))\n",
        "    z_bottom_crop = int(np.floor(z_diff / 2))\n",
        "    cropped_image = sitk.Crop(image, (0, 0, z_bottom_crop), (0, 0, z_top_crop))\n",
        "    return cropped_image\n",
        "\n",
        "\n",
        "def pad_xy(image, dimension, pad_filler):\n",
        "    image_size = image.GetSize()\n",
        "    xy_pad1 = int(np.ceil((dimension - image_size[0]) / 2))  # 256-250=6\n",
        "    xy_pad2 = int(np.floor((dimension - image_size[0]) / 2))\n",
        "    padded_image = sitk.ConstantPad(\n",
        "        image, (xy_pad1, xy_pad1, 0), (xy_pad2, xy_pad2, 0), pad_filler\n",
        "    )\n",
        "    return padded_image\n",
        "\n",
        "\n",
        "def crop_values(arr, config):\n",
        "    ranges = config.crop_ranges\n",
        "    if config.use_positive_values:\n",
        "        ranges = np.array(config.crop_ranges) + 1024\n",
        "    arrs = []\n",
        "    for idx, range in enumerate(ranges):\n",
        "        arrs.append(arr.copy())\n",
        "        arrs[idx][arrs[idx] < range[0]] = range[0]\n",
        "        arrs[idx][arrs[idx] > range[1]] = range[1]\n",
        "\n",
        "    result = reduce(lambda a, b: a + b, arrs)\n",
        "    return result\n",
        "\n",
        "\n",
        "def normalize(image_array, config):\n",
        "    norm_image_array = (image_array - config.crop_ranges[0][0]) / (\n",
        "        config.crop_ranges[-1][-1] - config.crop_ranges[0][0]\n",
        "    )\n",
        "    norm_image_array[norm_image_array > 1] = 1.0\n",
        "    norm_image_array[norm_image_array < 0] = 0.0\n",
        "    return norm_image_array\n",
        "\n",
        "\n",
        "def set_positive_values(image_array):\n",
        "    pos_image_array = image_array + 1024\n",
        "    return pos_image_array\n",
        "\n",
        "\n",
        "def set_direction(image, coord):\n",
        "    new_image = sitk.DICOMOrient(image, coord)\n",
        "    return new_image\n",
        "\n",
        "\n",
        "def set_dtype(image, target):\n",
        "    match target:\n",
        "        case Target.CT:\n",
        "            x = image.astype(dtype=np.float64)\n",
        "        case Target.LUNGS:\n",
        "            x = image.astype(dtype=np.int16)\n",
        "        case Target.EFFUSION:\n",
        "            x = image.astype(dtype=np.int16)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_final_image(\n",
        "    target=Target.CT, id=\"LUNG1-001\", config=Config(), coords=(\"LPS\", \"LAS\")\n",
        "):\n",
        "    x = get_initial_image(target, id)\n",
        "    if x is None:\n",
        "        return np.zeros(\n",
        "            (config.target_z, config.dimension, config.dimension, 1), dtype=np.int16\n",
        "        )\n",
        "\n",
        "    if config.resample_spacing:\n",
        "        x = resample_spacing(x)\n",
        "\n",
        "    if config.resample_size:\n",
        "        x = resample_size(x, config.resize_factor)\n",
        "\n",
        "    x = set_final_size(x, config.target_z, config.dimension, 0)\n",
        "\n",
        "    if target == Target.CT:\n",
        "        x = set_direction(x, coords[0])\n",
        "    else:\n",
        "        x = set_direction(x, coords[1])\n",
        "\n",
        "    x = sitk.GetArrayFromImage(x)\n",
        "\n",
        "    match target:\n",
        "        case Target.CT:\n",
        "            if config.use_positive_values:\n",
        "                x = set_positive_values(x)\n",
        "\n",
        "            if config.crop_values:\n",
        "                x = crop_values(x, config)\n",
        "\n",
        "            if config.normalize:\n",
        "                x = normalize(x)\n",
        "\n",
        "        case Target.LUNGS:\n",
        "            x = np.where(x > 0, 1, 0)\n",
        "\n",
        "    x = x.reshape(config.target_z, config.dimension, config.dimension, 1)\n",
        "    x = set_dtype(x, target)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def create_example(feature, label, shape):\n",
        "    feature = {\n",
        "        \"feature\": _bytes_feature(feature.tobytes()),\n",
        "        \"label\": _bytes_feature(label.tobytes()),\n",
        "        \"shape\": _bytes_feature(shape.tobytes()),\n",
        "    }\n",
        "\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_dataset(df, config):\n",
        "    record_file = os.path.join(config.dataset_path, f\"{df.name}.tfrecords\")\n",
        "    options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "    with tf.io.TFRecordWriter(record_file, options=options) as writer:\n",
        "        for id in df.index:\n",
        "            for coord in config.coords:\n",
        "                ct = get_final_image(\n",
        "                    target=Target.CT, id=id, config=config, coords=coord\n",
        "                )\n",
        "                mask = get_final_image(\n",
        "                    target=config.mask, id=id, config=config, coords=coord\n",
        "                )\n",
        "                ct_shape = np.array(ct.shape)\n",
        "\n",
        "                tf_example = create_example(ct, mask, ct_shape)\n",
        "                writer.write(tf_example.SerializeToString())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# FOR TESTING\\nCONFIGS = [\\n    Config(\\n        model_name=\"test_effusion\",\\n        resample_spacing=False,\\n        resample_size=True,\\n        resize_factor=2,\\n        normalize=False,\\n        use_positive_values=False,\\n        crop_values=True,\\n        crop_ranges=[[-1024, 200]],\\n        pad_filler=-1024,\\n        mask=Mask.EFFUSION,\\n        ratio=1 / 1,\\n        coords=COORDS,\\n    ),\\n    Config(\\n        model_name=\"test_lungs\",\\n        resample_spacing=False,\\n        resample_size=True,\\n        resize_factor=2,\\n        normalize=False,\\n        use_positive_values=False,\\n        crop_values=True,\\n        crop_ranges=[[-1024, 200]],\\n        pad_filler=-1024,\\n        mask=Mask.LUNGS,\\n        coords=COORDS,\\n    ),\\n]\\n'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CONFIGS = [\n",
        "    Config(\n",
        "        model_name=\"effusions_aug\",\n",
        "        resample_spacing=False,\n",
        "        resample_size=True,\n",
        "        resize_factor=2,\n",
        "        normalize=False,\n",
        "        use_positive_values=False,\n",
        "        crop_values=True,\n",
        "        crop_ranges=[[-1024, 200]],\n",
        "        pad_filler=-1024,\n",
        "        mask=Mask.EFFUSION,\n",
        "        ratio=1 / 1,\n",
        "        coords=COORDS,\n",
        "    ),\n",
        "    Config(\n",
        "        model_name=\"lungs_aug\",\n",
        "        resample_spacing=False,\n",
        "        resample_size=True,\n",
        "        resize_factor=2,\n",
        "        normalize=False,\n",
        "        use_positive_values=False,\n",
        "        crop_values=True,\n",
        "        crop_ranges=[[-1024, 200]],\n",
        "        pad_filler=-1024,\n",
        "        mask=Mask.LUNGS,\n",
        "        coords=COORDS,\n",
        "    ),\n",
        "]\n",
        "\n",
        "\"\"\"\n",
        "# FOR TESTING\n",
        "CONFIGS = [\n",
        "    Config(\n",
        "        model_name=\"test_effusion\",\n",
        "        resample_spacing=False,\n",
        "        resample_size=True,\n",
        "        resize_factor=2,\n",
        "        normalize=False,\n",
        "        use_positive_values=False,\n",
        "        crop_values=True,\n",
        "        crop_ranges=[[-1024, 200]],\n",
        "        pad_filler=-1024,\n",
        "        mask=Mask.EFFUSION,\n",
        "        ratio=1 / 1,\n",
        "        coords=COORDS,\n",
        "    ),\n",
        "    Config(\n",
        "        model_name=\"test_lungs\",\n",
        "        resample_spacing=False,\n",
        "        resample_size=True,\n",
        "        resize_factor=2,\n",
        "        normalize=False,\n",
        "        use_positive_values=False,\n",
        "        crop_values=True,\n",
        "        crop_ranges=[[-1024, 200]],\n",
        "        pad_filler=-1024,\n",
        "        mask=Mask.LUNGS,\n",
        "        coords=COORDS,\n",
        "    ),\n",
        "]\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Writing datasets for effusions_aug\n",
            "Amount of labels: 54\n",
            "Amount of features: 358\n",
            "Balanced df size: 108\n",
            "validation set size: 20\n",
            "test set size: 10\n",
            "train set size: 78\n",
            "\n",
            "Writing datasets for lungs_aug\n",
            "validation set size: 50\n",
            "test set size: 25\n",
            "train set size: 283\n"
          ]
        }
      ],
      "source": [
        "DATE_TIME = datetime.now().strftime(\"%d_%m_%Y__%H_%M_%S\")\n",
        "\n",
        "for config in CONFIGS:\n",
        "    print(f\"\\nWriting datasets for {config.model_name}\")\n",
        "    match config.mask:\n",
        "        case Mask.LUNGS:\n",
        "            train_df, val_df, test_df = get_lungs_dfs(use_latest=False)\n",
        "        case Mask.EFFUSION:\n",
        "            train_df, val_df, test_df = get_effusion_dfs(config.ratio, use_latest=False)\n",
        "    config.save_to_JSON()\n",
        "    get_dataset(train_df, config)\n",
        "    get_dataset(val_df, config)\n",
        "    get_dataset(test_df, config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# READ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_record(record):\n",
        "    name_to_features = {\n",
        "        \"feature\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"label\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"shape\": tf.io.FixedLenFeature([], tf.string),\n",
        "    }\n",
        "    return tf.io.parse_single_example(record, name_to_features)\n",
        "\n",
        "\n",
        "def decode_record(record, config):\n",
        "    feature = tf.io.decode_raw(\n",
        "        record[\"feature\"],\n",
        "        out_type=\"float64\",\n",
        "        little_endian=True,\n",
        "        fixed_length=None,\n",
        "        name=None,\n",
        "    )\n",
        "    label = tf.io.decode_raw(\n",
        "        record[\"label\"],\n",
        "        out_type=\"int16\",\n",
        "        little_endian=True,\n",
        "        fixed_length=None,\n",
        "        name=None,\n",
        "    )\n",
        "\n",
        "    shape = tf.io.decode_raw(\n",
        "        record[\"shape\"],\n",
        "        out_type=\"int64\",\n",
        "        little_endian=True,\n",
        "        fixed_length=None,\n",
        "        name=None,\n",
        "    )\n",
        "    label = tf.cast(\n",
        "        tf.reshape(label, (config.target_z, config.dimension, config.dimension, 1)),\n",
        "        dtype=tf.float32,\n",
        "    )\n",
        "\n",
        "    feature = tf.cast(\n",
        "        tf.reshape(feature, (config.target_z, config.dimension, config.dimension, 1)),\n",
        "        dtype=tf.float64,\n",
        "    )\n",
        "    label.set_shape((config.target_z, config.dimension, config.dimension, 1))\n",
        "\n",
        "    feature.set_shape((config.target_z, config.dimension, config.dimension, 1))\n",
        "    return (feature, label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_image(image, slice_num):\n",
        "    my_slice = image[slice_num, :, :]\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 5))\n",
        "    ax.imshow(feature_slice, cmap=\"bone\", interpolation=\"none\")\n",
        "    plt.title(f\"Slice {slice_num}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_overlay(feature, label):\n",
        "    mid_slice = int(feature.shape[0] / 2)\n",
        "    feature_slice = feature[mid_slice, :, :]\n",
        "    label_slice = np.squeeze(label[mid_slice, :, :])\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
        "    ax[0].imshow(feature_slice, cmap=\"bone\", interpolation=\"none\")\n",
        "    ax[1].imshow(feature_slice, cmap=\"bone\", interpolation=\"none\")\n",
        "    ax[1].imshow(\n",
        "        label_slice, cmap=\"prism\", vmin=0, vmax=1, alpha=0.5 * (np.squeeze(label_slice))\n",
        "    )\n",
        "    plt.title(f\"Slice {mid_slice}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_3d(\n",
        "    images,\n",
        "    colors=[[0.5, 0.5, 1], [0.9, 0.1, 0.9]],\n",
        "    alpha=[0.1, 0.9],\n",
        "    threshold=[-600, 0],\n",
        "):\n",
        "    \"\"\"\n",
        "    Эта функция создает 3D визуализацию изображения на основе заданного порогового значения.\n",
        "    Параметры:\n",
        "    images: [ndarray]\n",
        "        3D массив, представляющий изображения.\n",
        "    colors: [float]\n",
        "        Массив значений цвета фигур.\n",
        "    alpha: [float]\n",
        "        Массив значеий прозрачности фигур.\n",
        "    threshold: х, необязательный\n",
        "        Пороговое значение, используемое для создания 3D модели.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(9, 9))\n",
        "    ax = fig.add_subplot(111, projection=\"3d\")\n",
        "\n",
        "    for idx, image in enumerate(images):\n",
        "        # Расположим сканирование вертикально,\n",
        "        # так чтобы голова пациента была вверху, лицом к камере\n",
        "        image = image.transpose(2, 0, 1)\n",
        "        image = image[:, :, ::-1]\n",
        "\n",
        "        if idx == 0:\n",
        "            # Устанавливаем границы для каждой оси в соответствии с формой транспонированного изображения\n",
        "            ax.set_xlim(0, image.shape[0])\n",
        "            ax.set_ylim(0, image.shape[1])\n",
        "            ax.set_zlim(0, image.shape[2])\n",
        "\n",
        "        # Получаем вершины и грани 3D модели, используя marching_cubes\n",
        "        verts, faces, _, _ = measure.marching_cubes(image, threshold[idx])\n",
        "        # Создаем объект Figure в matplotlib и добавляем в него 3D подзаголовок\n",
        "\n",
        "        # Создаем коллекцию треугольников из вершин и граней, устанавливаем цвет и прозрачность, добавляем в подзаголовок\n",
        "        mesh = Poly3DCollection(verts[faces], alpha=alpha[idx])\n",
        "        face_color = colors[idx]\n",
        "        mesh.set_facecolor(face_color)\n",
        "        ax.add_collection3d(mesh)\n",
        "\n",
        "    # Отображаем визуализацию\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def overlay_slices_slider(images, titles=[], cmaps=[\"bone\", \"prism\", \"jet\"]):\n",
        "    @widgets.interact(axial_slice=(0, images[0].shape[0] - 1))\n",
        "    def axial_slicer(axial_slice=0):\n",
        "        num_plots = len(images)\n",
        "        if len(titles) < num_plots:\n",
        "            diff = num_plots - len(titles)\n",
        "            for i in range(diff):\n",
        "                titles.append(\"\")\n",
        "        fig, ax = plt.subplots(1, num_plots, figsize=(5 * num_plots, 5), squeeze=False)\n",
        "        ax[0][0].imshow(images[0][axial_slice, :, :], cmap=cmaps[0])\n",
        "        ax[0][0].set_title(titles[0])\n",
        "        ax[0][0].axis(\"off\")\n",
        "        for x in range(num_plots - 1):\n",
        "            ax[0][x + 1].imshow(images[0][axial_slice, :, :], cmap=cmaps[0])\n",
        "            ax[0][x + 1].imshow(\n",
        "                images[x + 1][axial_slice, :, :],\n",
        "                cmap=cmaps[x + 1],\n",
        "                alpha=0.5 * images[x + 1][axial_slice],\n",
        "            )\n",
        "            ax[0][x + 1].set_title(titles[x + 1])\n",
        "            ax[0][x + 1].axis(\"off\")\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for config in CONFIGS[:1]:\n",
        "    print(\"Reading data for model:\", config.model_name)\n",
        "    print(config.dataset_path)\n",
        "    record_file = os.path.join(config.dataset_path, \"test.tfrecords\")\n",
        "    dataset = tf.data.TFRecordDataset(record_file, compression_type=\"GZIP\")\n",
        "\n",
        "    for record in dataset:\n",
        "        parsed_record = parse_record(record)\n",
        "        feature, label = decode_record(parsed_record, config)\n",
        "        feature = feature.numpy().squeeze()\n",
        "        label = label.numpy().squeeze()\n",
        "        # plot_overlay(feature, label)\n",
        "        overlay_slices_slider(\n",
        "            images=[feature, label],\n",
        "            titles=[\"Feature\", \"Lungs\"],\n",
        "            cmaps=[\"bone\", \"prism\"],\n",
        "        )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPaax9+gZhwiRJ19qYIZcN6",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
